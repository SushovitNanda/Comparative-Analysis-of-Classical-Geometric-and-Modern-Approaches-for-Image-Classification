{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ROBUSTNESS STUDY - DATASET PREPROCESSING\n",
            "============================================================\n",
            "[OK] Sufficient memory (15.6GB). Batch size: 200\n",
            "\n",
            "============================================================\n",
            "Loading MNIST Dataset\n",
            "============================================================\n",
            "Converting to numpy arrays...\n",
            "Resizing to (128, 128)...\n",
            "  Resizing: 0/60000 images processed\n",
            "  Resizing: 1000/60000 images processed\n",
            "  Resizing: 2000/60000 images processed\n",
            "  Resizing: 3000/60000 images processed\n",
            "  Resizing: 4000/60000 images processed\n",
            "  Resizing: 5000/60000 images processed\n",
            "  Resizing: 6000/60000 images processed\n",
            "  Resizing: 7000/60000 images processed\n",
            "  Resizing: 8000/60000 images processed\n",
            "  Resizing: 9000/60000 images processed\n",
            "  Resizing: 10000/60000 images processed\n",
            "  Resizing: 11000/60000 images processed\n",
            "  Resizing: 12000/60000 images processed\n",
            "  Resizing: 13000/60000 images processed\n",
            "  Resizing: 14000/60000 images processed\n",
            "  Resizing: 15000/60000 images processed\n",
            "  Resizing: 16000/60000 images processed\n",
            "  Resizing: 17000/60000 images processed\n",
            "  Resizing: 18000/60000 images processed\n",
            "  Resizing: 19000/60000 images processed\n",
            "  Resizing: 20000/60000 images processed\n",
            "  Resizing: 21000/60000 images processed\n",
            "  Resizing: 22000/60000 images processed\n",
            "  Resizing: 23000/60000 images processed\n",
            "  Resizing: 24000/60000 images processed\n",
            "  Resizing: 25000/60000 images processed\n",
            "  Resizing: 26000/60000 images processed\n",
            "  Resizing: 27000/60000 images processed\n",
            "  Resizing: 28000/60000 images processed\n",
            "  Resizing: 29000/60000 images processed\n",
            "  Resizing: 30000/60000 images processed\n",
            "  Resizing: 31000/60000 images processed\n",
            "  Resizing: 32000/60000 images processed\n",
            "  Resizing: 33000/60000 images processed\n",
            "  Resizing: 34000/60000 images processed\n",
            "  Resizing: 35000/60000 images processed\n",
            "  Resizing: 36000/60000 images processed\n",
            "  Resizing: 37000/60000 images processed\n",
            "  Resizing: 38000/60000 images processed\n",
            "  Resizing: 39000/60000 images processed\n",
            "  Resizing: 40000/60000 images processed\n",
            "  Resizing: 41000/60000 images processed\n",
            "  Resizing: 42000/60000 images processed\n",
            "  Resizing: 43000/60000 images processed\n",
            "  Resizing: 44000/60000 images processed\n",
            "  Resizing: 45000/60000 images processed\n",
            "  Resizing: 46000/60000 images processed\n",
            "  Resizing: 47000/60000 images processed\n",
            "  Resizing: 48000/60000 images processed\n",
            "  Resizing: 49000/60000 images processed\n",
            "  Resizing: 50000/60000 images processed\n",
            "  Resizing: 51000/60000 images processed\n",
            "  Resizing: 52000/60000 images processed\n",
            "  Resizing: 53000/60000 images processed\n",
            "  Resizing: 54000/60000 images processed\n",
            "  Resizing: 55000/60000 images processed\n",
            "  Resizing: 56000/60000 images processed\n",
            "  Resizing: 57000/60000 images processed\n",
            "  Resizing: 58000/60000 images processed\n",
            "  Resizing: 59000/60000 images processed\n",
            "  Resizing: 0/10000 images processed\n",
            "  Resizing: 1000/10000 images processed\n",
            "  Resizing: 2000/10000 images processed\n",
            "  Resizing: 3000/10000 images processed\n",
            "  Resizing: 4000/10000 images processed\n",
            "  Resizing: 5000/10000 images processed\n",
            "  Resizing: 6000/10000 images processed\n",
            "  Resizing: 7000/10000 images processed\n",
            "  Resizing: 8000/10000 images processed\n",
            "  Resizing: 9000/10000 images processed\n",
            "[OK] MNIST loaded: 60000 train, 10000 test\n",
            "\n",
            "============================================================\n",
            "Creating Augmented Datasets for MNIST\n",
            "============================================================\n",
            "  Creating augmented training set with 60000 samples...\n",
            "    Processing original split...\n",
            "    Processing rotation split...\n",
            "    Processing noise split...\n",
            "    Processing scaling split...\n",
            "    Processing occlusion split...\n",
            "  [OK] Saved 3 samples: ./data\\processed\\samples\\mnist\\mixed_augmented_train.png\n",
            "    Creating combined augmentation training set...\n",
            "      Processing chunk 0-5000...\n",
            "      Processing chunk 5000-10000...\n",
            "      Processing chunk 10000-15000...\n",
            "      Processing chunk 15000-20000...\n",
            "      Processing chunk 20000-25000...\n",
            "      Processing chunk 25000-30000...\n",
            "      Processing chunk 30000-35000...\n",
            "      Processing chunk 35000-40000...\n",
            "      Processing chunk 40000-45000...\n",
            "      Processing chunk 45000-50000...\n",
            "      Processing chunk 50000-55000...\n",
            "      Processing chunk 55000-60000...\n",
            "  [OK] Saved 3 samples: ./data\\processed\\samples\\mnist\\combined_augmented_train.png\n",
            "  [OK] Saved 3 samples: ./data\\processed\\samples\\mnist\\original_train.png\n",
            "  Creating augmented test sets with 10000 samples...\n",
            "    Creating and saving original test set...\n",
            "  [OK] Saved 3 samples: ./data\\processed\\samples\\mnist\\original_test.png\n",
            "    Creating and saving rotation_15 test set...\n",
            "  [OK] Saved 3 samples: ./data\\processed\\samples\\mnist\\rotation_15_test.png\n",
            "    Creating and saving noise test set...\n",
            "  [OK] Saved 3 samples: ./data\\processed\\samples\\mnist\\noise_test.png\n",
            "    Creating and saving scaling_0.8 test set...\n",
            "  [OK] Saved 3 samples: ./data\\processed\\samples\\mnist\\scaling_0.8_test.png\n",
            "    Creating and saving occlusion_25 test set...\n",
            "  [OK] Saved 3 samples: ./data\\processed\\samples\\mnist\\occlusion_25_test.png\n",
            "    Creating and saving combined augmentation test set...\n",
            "  [OK] Saved 3 samples: ./data\\processed\\samples\\mnist\\all_combined_test.png\n",
            "\n",
            "Saving MNIST datasets...\n",
            "\n",
            "Saving mnist datasets separately...\n",
            "[OK] Saved original data: 4375.53 MB\n",
            "[OK] Saved original train: 3750.46 MB\n",
            "[OK] Saved mixed_augmented train: 3750.46 MB\n",
            "[OK] Saved combined_augmented train: 3750.46 MB\n",
            "[OK] Saved original test: 625.08 MB\n",
            "[OK] Saved rotation_15 test: 625.08 MB\n",
            "[OK] Saved noise test: 625.08 MB\n",
            "[OK] Saved scaling_0.8 test: 625.08 MB\n",
            "[OK] Saved occlusion_25 test: 625.08 MB\n",
            "[OK] Saved all_combined test: 625.08 MB\n",
            "[OK] Saved metadata\n",
            "\n",
            "============================================================\n",
            "MNIST - Dataset Statistics\n",
            "============================================================\n",
            "\n",
            "TRAINING SETS:\n",
            "  ORIGINAL            :  60000 samples, shape: (128, 128, 1)\n",
            "  MIXED_AUGMENTED     :  60000 samples, shape: (128, 128, 1)\n",
            "  COMBINED_AUGMENTED  :  60000 samples, shape: (128, 128, 1)\n",
            "\n",
            "TEST SETS:\n",
            "  ORIGINAL            :  10000 samples, shape: (128, 128, 1)\n",
            "  ROTATION_15         :  10000 samples, shape: (128, 128, 1)\n",
            "  NOISE               :  10000 samples, shape: (128, 128, 1)\n",
            "  SCALING_0.8         :  10000 samples, shape: (128, 128, 1)\n",
            "  OCCLUSION_25        :  10000 samples, shape: (128, 128, 1)\n",
            "  ALL_COMBINED        :  10000 samples, shape: (128, 128, 1)\n",
            "\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Creating Visualizations\n",
            "============================================================\n",
            "\n",
            "Creating MNIST visualizations...\n",
            "[OK] Saved comparison to ./data\\processed\\MNIST_augmentation_comparison.png\n",
            "\n",
            "============================================================\n",
            "[OK] PREPROCESSING COMPLETE\n",
            "============================================================\n",
            "\n",
            "Generated datasets for robustness study:\n",
            "\n",
            "TRAINING SETS (3 versions per dataset):\n",
            "  1. original - Clean training data\n",
            "  2. mixed_augmented - Equal parts: original + rotation + noise + scaling + occlusion\n",
            "  3. combined_augmented - All augmentations applied to every sample\n",
            "\n",
            "TEST SETS (6 versions per dataset):\n",
            "  1. original - Clean test data\n",
            "  2. rotation_15 - 15° rotation\n",
            "  3. noise - Gaussian noise\n",
            "  4. scaling_0.8 - 0.8x scaling\n",
            "  5. occlusion_25 - 25% occlusion\n",
            "  6. all_combined - All augmentations combined\n",
            "\n",
            "Processed data saved in: ./data\\processed\n",
            "Sample images saved in: ./data\\processed\\samples\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pickle\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import gc\n",
        "import psutil\n",
        "\n",
        "class DatasetPreprocessor:\n",
        "    def __init__(self, data_dir='./data', img_size=(128, 128), batch_size=500):\n",
        "        \"\"\"\n",
        "        Initialize dataset preprocessor for robustness study\n",
        "        \"\"\"\n",
        "        self.data_dir = data_dir\n",
        "        self.img_size = img_size\n",
        "        self.batch_size = batch_size\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        \n",
        "        self.processed_dir = os.path.join(data_dir, 'processed')\n",
        "        os.makedirs(self.processed_dir, exist_ok=True)\n",
        "        \n",
        "        # Create samples directory\n",
        "        self.samples_dir = os.path.join(self.processed_dir, 'samples')\n",
        "        os.makedirs(self.samples_dir, exist_ok=True)\n",
        "        \n",
        "        # Auto-adjust batch size based on available memory\n",
        "        self._auto_adjust_batch_size()\n",
        "    \n",
        "    def _auto_adjust_batch_size(self):\n",
        "        \"\"\"Automatically adjust batch size based on available memory\"\"\"\n",
        "        try:\n",
        "            available_memory_gb = psutil.virtual_memory().available / (1024 ** 3)\n",
        "            \n",
        "            if available_memory_gb < 2:\n",
        "                self.batch_size = min(self.batch_size, 50)\n",
        "                print(f\"[WARNING] Low memory detected ({available_memory_gb:.1f}GB). Batch size reduced to {self.batch_size}\")\n",
        "            elif available_memory_gb < 4:\n",
        "                self.batch_size = min(self.batch_size, 100)\n",
        "                print(f\"[INFO] Moderate memory ({available_memory_gb:.1f}GB). Batch size set to {self.batch_size}\")\n",
        "            else:\n",
        "                print(f\"[OK] Sufficient memory ({available_memory_gb:.1f}GB). Batch size: {self.batch_size}\")\n",
        "        except:\n",
        "            print(\"[INFO] Could not detect memory. Using default batch size.\")\n",
        "    \n",
        "    def _check_memory_and_collect(self):\n",
        "        \"\"\"Check memory usage and collect garbage if needed\"\"\"\n",
        "        try:\n",
        "            memory_percent = psutil.virtual_memory().percent\n",
        "            if memory_percent > 85:\n",
        "                gc.collect()\n",
        "                if memory_percent > 90:\n",
        "                    print(f\"[WARNING] High memory usage ({memory_percent:.1f}%). Forcing garbage collection...\")\n",
        "        except:\n",
        "            gc.collect()\n",
        "    \n",
        "    def save_sample_images(self, images, labels, class_names, aug_type, dataset_name, n_samples=3):\n",
        "        \"\"\"Save sample images for a given augmentation type\"\"\"\n",
        "        # Create subdirectory for this dataset\n",
        "        dataset_samples_dir = os.path.join(self.samples_dir, dataset_name)\n",
        "        os.makedirs(dataset_samples_dir, exist_ok=True)\n",
        "        \n",
        "        # Select random samples\n",
        "        n_samples = min(n_samples, len(images))\n",
        "        sample_indices = np.random.choice(len(images), n_samples, replace=False)\n",
        "        \n",
        "        # Create a figure with samples\n",
        "        fig, axes = plt.subplots(1, n_samples, figsize=(4*n_samples, 4))\n",
        "        if n_samples == 1:\n",
        "            axes = [axes]\n",
        "        \n",
        "        for idx, sample_idx in enumerate(sample_indices):\n",
        "            img = images[sample_idx]\n",
        "            label = labels[sample_idx]\n",
        "            class_name = class_names[label]\n",
        "            \n",
        "            # Display image\n",
        "            if img.shape[-1] == 1:\n",
        "                axes[idx].imshow(img.squeeze(), cmap='gray')\n",
        "            else:\n",
        "                axes[idx].imshow(img)\n",
        "            \n",
        "            axes[idx].set_title(f'Class: {class_name}', fontsize=10)\n",
        "            axes[idx].axis('off')\n",
        "        \n",
        "        plt.suptitle(f'{dataset_name} - {aug_type}', fontsize=12, y=0.98)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Save figure\n",
        "        save_path = os.path.join(dataset_samples_dir, f'{aug_type}.png')\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        \n",
        "        print(f\"  [OK] Saved {n_samples} samples: {save_path}\")\n",
        "        gc.collect()\n",
        "    \n",
        "    def resize_images_batch(self, images, target_size):\n",
        "        \"\"\"Resize images in batches to avoid memory issues\"\"\"\n",
        "        total = len(images)\n",
        "        resized = []\n",
        "        \n",
        "        # Use smaller sub-batches for resizing\n",
        "        sub_batch_size = min(self.batch_size, 100)\n",
        "        \n",
        "        for i in range(0, total, sub_batch_size):\n",
        "            batch_end = min(i + sub_batch_size, total)\n",
        "            if i % (sub_batch_size * 10) == 0:\n",
        "                print(f\"  Resizing: {i}/{total} images processed\")\n",
        "                self._check_memory_and_collect()\n",
        "            \n",
        "            batch = images[i:batch_end]\n",
        "            batch_resized = [cv2.resize(img, target_size) for img in batch]\n",
        "            resized.extend(batch_resized)\n",
        "            \n",
        "            del batch, batch_resized\n",
        "        \n",
        "        gc.collect()\n",
        "        return np.array(resized)\n",
        "    \n",
        "    def apply_rotation(self, images, angle):\n",
        "        \"\"\"Apply rotation augmentation in batches\"\"\"\n",
        "        rotated = []\n",
        "        sub_batch_size = min(self.batch_size, 100)\n",
        "        \n",
        "        for i in range(0, len(images), sub_batch_size):\n",
        "            batch_end = min(i + sub_batch_size, len(images))\n",
        "            batch = images[i:batch_end]\n",
        "            \n",
        "            batch_rotated = []\n",
        "            for img in batch:\n",
        "                if len(img.shape) == 3 and img.shape[-1] == 1:\n",
        "                    img_2d = img.squeeze(axis=-1)\n",
        "                    img_pil = Image.fromarray(img_2d.astype('uint8'))\n",
        "                    rotated_pil = img_pil.rotate(angle, fillcolor=0)\n",
        "                    rotated_np = np.expand_dims(np.array(rotated_pil), axis=-1)\n",
        "                else:\n",
        "                    img_pil = Image.fromarray(img.astype('uint8'))\n",
        "                    rotated_pil = img_pil.rotate(angle, fillcolor=0)\n",
        "                    rotated_np = np.array(rotated_pil)\n",
        "                batch_rotated.append(rotated_np)\n",
        "            \n",
        "            rotated.extend(batch_rotated)\n",
        "            del batch, batch_rotated\n",
        "            \n",
        "            if i % (sub_batch_size * 5) == 0:\n",
        "                self._check_memory_and_collect()\n",
        "        \n",
        "        return np.array(rotated)\n",
        "    \n",
        "    def apply_noise(self, images):\n",
        "        \"\"\"Apply Gaussian noise augmentation in batches\"\"\"\n",
        "        noisy = []\n",
        "        sub_batch_size = min(self.batch_size, 100)\n",
        "        \n",
        "        for i in range(0, len(images), sub_batch_size):\n",
        "            batch_end = min(i + sub_batch_size, len(images))\n",
        "            batch = images[i:batch_end]\n",
        "            \n",
        "            # Generate noise for entire batch at once (more efficient)\n",
        "            noise = np.random.normal(0, 25, batch.shape).astype(np.float32)\n",
        "            batch_noisy = np.clip(batch.astype(np.float32) + noise, 0, 255).astype(np.uint8)\n",
        "            \n",
        "            noisy.extend(batch_noisy)\n",
        "            del batch, noise, batch_noisy\n",
        "            \n",
        "            if i % (sub_batch_size * 5) == 0:\n",
        "                self._check_memory_and_collect()\n",
        "        \n",
        "        return np.array(noisy)\n",
        "    \n",
        "    def apply_scaling(self, images, scale):\n",
        "        \"\"\"Apply scaling augmentation in batches\"\"\"\n",
        "        scaled = []\n",
        "        sub_batch_size = min(self.batch_size, 100)\n",
        "        \n",
        "        for i in range(0, len(images), sub_batch_size):\n",
        "            batch_end = min(i + sub_batch_size, len(images))\n",
        "            batch = images[i:batch_end]\n",
        "            \n",
        "            batch_scaled = []\n",
        "            for img in batch:\n",
        "                h, w = img.shape[:2]\n",
        "                new_h, new_w = int(h * scale), int(w * scale)\n",
        "                \n",
        "                if len(img.shape) == 3 and img.shape[-1] == 1:\n",
        "                    img_2d = img.squeeze(axis=-1)\n",
        "                    img_pil = Image.fromarray(img_2d.astype('uint8'))\n",
        "                    scaled_pil = img_pil.resize((new_w, new_h))\n",
        "                    final_pil = Image.new('L', (w, h), color=0)\n",
        "                    paste_x = max(0, (w - new_w) // 2)\n",
        "                    paste_y = max(0, (h - new_h) // 2)\n",
        "                    final_pil.paste(scaled_pil, (paste_x, paste_y))\n",
        "                    scaled_np = np.expand_dims(np.array(final_pil), axis=-1)\n",
        "                else:\n",
        "                    img_pil = Image.fromarray(img.astype('uint8'))\n",
        "                    scaled_pil = img_pil.resize((new_w, new_h))\n",
        "                    final_pil = Image.new('RGB', (w, h), color=0)\n",
        "                    paste_x = max(0, (w - new_w) // 2)\n",
        "                    paste_y = max(0, (h - new_h) // 2)\n",
        "                    final_pil.paste(scaled_pil, (paste_x, paste_y))\n",
        "                    scaled_np = np.array(final_pil)\n",
        "                \n",
        "                batch_scaled.append(scaled_np)\n",
        "            \n",
        "            scaled.extend(batch_scaled)\n",
        "            del batch, batch_scaled\n",
        "            \n",
        "            if i % (sub_batch_size * 5) == 0:\n",
        "                self._check_memory_and_collect()\n",
        "        \n",
        "        return np.array(scaled)\n",
        "    \n",
        "    def apply_occlusion(self, images, occlusion_ratio=0.25):\n",
        "        \"\"\"Apply occlusion augmentation in batches\"\"\"\n",
        "        occluded = []\n",
        "        occlusion_size = int(min(self.img_size) * occlusion_ratio)\n",
        "        sub_batch_size = min(self.batch_size, 100)\n",
        "        \n",
        "        for i in range(0, len(images), sub_batch_size):\n",
        "            batch_end = min(i + sub_batch_size, len(images))\n",
        "            batch = images[i:batch_end].copy()\n",
        "            \n",
        "            # Apply occlusion to batch\n",
        "            for j in range(len(batch)):\n",
        "                h, w = batch[j].shape[:2]\n",
        "                x = np.random.randint(0, max(1, w - occlusion_size))\n",
        "                y = np.random.randint(0, max(1, h - occlusion_size))\n",
        "                batch[j][y:y+occlusion_size, x:x+occlusion_size] = 0\n",
        "            \n",
        "            occluded.extend(batch)\n",
        "            del batch\n",
        "            \n",
        "            if i % (sub_batch_size * 5) == 0:\n",
        "                self._check_memory_and_collect()\n",
        "        \n",
        "        return np.array(occluded)\n",
        "    \n",
        "    def create_augmented_test_sets(self, images, labels, class_names, dataset_name):\n",
        "        \"\"\"\n",
        "        Create all augmented test datasets using entire test set\n",
        "        Process and save each augmentation immediately to minimize memory\n",
        "        \"\"\"\n",
        "        print(f\"  Creating augmented test sets with {len(images)} samples...\")\n",
        "        \n",
        "        # Convert to uint8 for augmentation\n",
        "        images_uint8 = (images * 255).astype('uint8')\n",
        "        \n",
        "        # 1. Original dataset - save immediately\n",
        "        print(\"    Creating and saving original test set...\")\n",
        "        test_dir = os.path.join(self.processed_dir, 'temp_test')\n",
        "        os.makedirs(test_dir, exist_ok=True)\n",
        "        \n",
        "        original_data = {'images': images.copy(), 'labels': labels.copy()}\n",
        "        with open(os.path.join(test_dir, 'original.pkl'), 'wb') as f:\n",
        "            pickle.dump(original_data, f)\n",
        "        \n",
        "        # Save samples for original\n",
        "        self.save_sample_images(images, labels, class_names, 'original_test', dataset_name)\n",
        "        \n",
        "        del original_data\n",
        "        gc.collect()\n",
        "        \n",
        "        # Process each augmentation separately and save immediately\n",
        "        augmentations = [\n",
        "            ('rotation_15', lambda x: self.apply_rotation(x, 15)),\n",
        "            ('noise', self.apply_noise),\n",
        "            ('scaling_0.8', lambda x: self.apply_scaling(x, 0.8)),\n",
        "            ('occlusion_25', lambda x: self.apply_occlusion(x, 0.25))\n",
        "        ]\n",
        "        \n",
        "        for aug_name, aug_func in augmentations:\n",
        "            print(f\"    Creating and saving {aug_name} test set...\")\n",
        "            augmented = aug_func(images_uint8)\n",
        "            augmented_normalized = augmented.astype('float32') / 255.0\n",
        "            augmented_data = {\n",
        "                'images': augmented_normalized,\n",
        "                'labels': labels.copy()\n",
        "            }\n",
        "            with open(os.path.join(test_dir, f'{aug_name}.pkl'), 'wb') as f:\n",
        "                pickle.dump(augmented_data, f)\n",
        "            \n",
        "            # Save samples for this augmentation\n",
        "            self.save_sample_images(augmented_normalized, labels, class_names, f'{aug_name}_test', dataset_name)\n",
        "            \n",
        "            del augmented, augmented_normalized, augmented_data\n",
        "            gc.collect()\n",
        "        \n",
        "        # 6. All combined - process in smaller chunks\n",
        "        print(\"    Creating and saving combined augmentation test set...\")\n",
        "        combined = images_uint8.copy()\n",
        "        combined = self.apply_rotation(combined, 15)\n",
        "        gc.collect()\n",
        "        combined = self.apply_noise(combined)\n",
        "        gc.collect()\n",
        "        combined = self.apply_scaling(combined, 0.8)\n",
        "        gc.collect()\n",
        "        combined = self.apply_occlusion(combined, 0.25)\n",
        "        \n",
        "        combined_normalized = combined.astype('float32') / 255.0\n",
        "        combined_data = {\n",
        "            'images': combined_normalized,\n",
        "            'labels': labels.copy()\n",
        "        }\n",
        "        with open(os.path.join(test_dir, 'all_combined.pkl'), 'wb') as f:\n",
        "            pickle.dump(combined_data, f)\n",
        "        \n",
        "        # Save samples for combined\n",
        "        self.save_sample_images(combined_normalized, labels, class_names, 'all_combined_test', dataset_name)\n",
        "        \n",
        "        del combined, combined_normalized, combined_data, images_uint8\n",
        "        gc.collect()\n",
        "        \n",
        "        # Load all datasets back\n",
        "        augmented_datasets = {}\n",
        "        for name in ['original', 'rotation_15', 'noise', 'scaling_0.8', 'occlusion_25', 'all_combined']:\n",
        "            with open(os.path.join(test_dir, f'{name}.pkl'), 'rb') as f:\n",
        "                augmented_datasets[name] = pickle.load(f)\n",
        "        \n",
        "        return augmented_datasets\n",
        "    \n",
        "    def create_augmented_train_set(self, images, labels, class_names, dataset_name):\n",
        "        \"\"\"\n",
        "        Create augmented training set with mixed augmentations\n",
        "        Process and save incrementally to minimize memory\n",
        "        \"\"\"\n",
        "        print(f\"  Creating augmented training set with {len(images)} samples...\")\n",
        "        \n",
        "        # Convert to uint8 for augmentation\n",
        "        images_uint8 = (images * 255).astype('uint8')\n",
        "        \n",
        "        # Split into 5 equal parts\n",
        "        n_samples = len(images)\n",
        "        split_size = n_samples // 5\n",
        "        indices = np.random.permutation(n_samples)\n",
        "        \n",
        "        # Create temp directory for intermediate storage\n",
        "        train_dir = os.path.join(self.processed_dir, 'temp_train')\n",
        "        os.makedirs(train_dir, exist_ok=True)\n",
        "        \n",
        "        # Process mixed augmentation splits\n",
        "        augmented_images = []\n",
        "        augmented_labels = []\n",
        "        \n",
        "        splits_data = []\n",
        "        for i in range(5):\n",
        "            start_idx = i * split_size\n",
        "            end_idx = (i + 1) * split_size if i < 4 else n_samples\n",
        "            split_indices = indices[start_idx:end_idx]\n",
        "            splits_data.append((images_uint8[split_indices], labels[split_indices]))\n",
        "        \n",
        "        # Split 0: Original\n",
        "        print(\"    Processing original split...\")\n",
        "        augmented_images.extend(splits_data[0][0])\n",
        "        augmented_labels.extend(splits_data[0][1])\n",
        "        \n",
        "        # Split 1: Rotation\n",
        "        print(\"    Processing rotation split...\")\n",
        "        rotated = self.apply_rotation(splits_data[1][0], 15)\n",
        "        augmented_images.extend(rotated)\n",
        "        augmented_labels.extend(splits_data[1][1])\n",
        "        del rotated\n",
        "        gc.collect()\n",
        "        \n",
        "        # Split 2: Noise\n",
        "        print(\"    Processing noise split...\")\n",
        "        noisy = self.apply_noise(splits_data[2][0])\n",
        "        augmented_images.extend(noisy)\n",
        "        augmented_labels.extend(splits_data[2][1])\n",
        "        del noisy\n",
        "        gc.collect()\n",
        "        \n",
        "        # Split 3: Scaling\n",
        "        print(\"    Processing scaling split...\")\n",
        "        scaled = self.apply_scaling(splits_data[3][0], 0.8)\n",
        "        augmented_images.extend(scaled)\n",
        "        augmented_labels.extend(splits_data[3][1])\n",
        "        del scaled\n",
        "        gc.collect()\n",
        "        \n",
        "        # Split 4: Occlusion\n",
        "        print(\"    Processing occlusion split...\")\n",
        "        occluded = self.apply_occlusion(splits_data[4][0], 0.25)\n",
        "        augmented_images.extend(occluded)\n",
        "        augmented_labels.extend(splits_data[4][1])\n",
        "        del occluded\n",
        "        gc.collect()\n",
        "        \n",
        "        # Convert to arrays and normalize\n",
        "        augmented_images = np.array(augmented_images).astype('float32') / 255.0\n",
        "        augmented_labels = np.array(augmented_labels)\n",
        "        \n",
        "        # Save mixed augmented immediately\n",
        "        mixed_data = {'images': augmented_images, 'labels': augmented_labels}\n",
        "        with open(os.path.join(train_dir, 'mixed_augmented.pkl'), 'wb') as f:\n",
        "            pickle.dump(mixed_data, f)\n",
        "        \n",
        "        # Save samples for mixed augmented\n",
        "        self.save_sample_images(augmented_images, augmented_labels, class_names, 'mixed_augmented_train', dataset_name)\n",
        "        \n",
        "        del augmented_images, augmented_labels, mixed_data\n",
        "        gc.collect()\n",
        "        \n",
        "        # Create combined augmentation version in chunks\n",
        "        print(\"    Creating combined augmentation training set...\")\n",
        "        combined_images = []\n",
        "        chunk_size = 5000  # Process in smaller chunks\n",
        "        \n",
        "        for i in range(0, len(images_uint8), chunk_size):\n",
        "            chunk_end = min(i + chunk_size, len(images_uint8))\n",
        "            print(f\"      Processing chunk {i}-{chunk_end}...\")\n",
        "            \n",
        "            chunk = images_uint8[i:chunk_end].copy()\n",
        "            chunk = self.apply_rotation(chunk, 15)\n",
        "            chunk = self.apply_noise(chunk)\n",
        "            chunk = self.apply_scaling(chunk, 0.8)\n",
        "            chunk = self.apply_occlusion(chunk, 0.25)\n",
        "            chunk = chunk.astype('float32') / 255.0\n",
        "            \n",
        "            combined_images.append(chunk)\n",
        "            del chunk\n",
        "            gc.collect()\n",
        "        \n",
        "        combined = np.concatenate(combined_images, axis=0)\n",
        "        del combined_images\n",
        "        gc.collect()\n",
        "        \n",
        "        # Save combined augmented\n",
        "        combined_data = {'images': combined, 'labels': labels.copy()}\n",
        "        with open(os.path.join(train_dir, 'combined_augmented.pkl'), 'wb') as f:\n",
        "            pickle.dump(combined_data, f)\n",
        "        \n",
        "        # Save samples for combined augmented\n",
        "        self.save_sample_images(combined, labels, class_names, 'combined_augmented_train', dataset_name)\n",
        "        \n",
        "        del combined, combined_data\n",
        "        gc.collect()\n",
        "        \n",
        "        # Save original\n",
        "        original_data = {'images': images.copy(), 'labels': labels.copy()}\n",
        "        with open(os.path.join(train_dir, 'original.pkl'), 'wb') as f:\n",
        "            pickle.dump(original_data, f)\n",
        "        \n",
        "        # Save samples for original train\n",
        "        self.save_sample_images(images, labels, class_names, 'original_train', dataset_name)\n",
        "        \n",
        "        del original_data\n",
        "        gc.collect()\n",
        "        \n",
        "        # Load all datasets back\n",
        "        train_datasets = {}\n",
        "        for name in ['original', 'mixed_augmented', 'combined_augmented']:\n",
        "            with open(os.path.join(train_dir, f'{name}.pkl'), 'rb') as f:\n",
        "                train_datasets[name] = pickle.load(f)\n",
        "        \n",
        "        return train_datasets\n",
        "    \n",
        "    def load_mnist(self):\n",
        "        \"\"\"Load and preprocess MNIST (grayscale dataset)\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Loading MNIST Dataset\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        # Download dataset\n",
        "        trainset = torchvision.datasets.MNIST(\n",
        "            root=self.data_dir, train=True, download=True\n",
        "        )\n",
        "        testset = torchvision.datasets.MNIST(\n",
        "            root=self.data_dir, train=False, download=True\n",
        "        )\n",
        "        \n",
        "        # Convert to numpy\n",
        "        print(\"Converting to numpy arrays...\")\n",
        "        train_images = trainset.data.numpy()\n",
        "        train_labels = trainset.targets.numpy()\n",
        "        test_images = testset.data.numpy()\n",
        "        test_labels = testset.targets.numpy()\n",
        "        \n",
        "        # Resize images\n",
        "        print(f\"Resizing to {self.img_size}...\")\n",
        "        train_images_resized = self.resize_images_batch(train_images, self.img_size)\n",
        "        gc.collect()\n",
        "        test_images_resized = self.resize_images_batch(test_images, self.img_size)\n",
        "        gc.collect()\n",
        "        \n",
        "        # Add channel dimension for consistency\n",
        "        train_images_resized = np.expand_dims(train_images_resized, axis=-1)\n",
        "        test_images_resized = np.expand_dims(test_images_resized, axis=-1)\n",
        "        \n",
        "        # Normalize to [0, 1] range\n",
        "        train_images_resized = train_images_resized.astype('float32') / 255.0\n",
        "        test_images_resized = test_images_resized.astype('float32') / 255.0\n",
        "        \n",
        "        mnist_data = {\n",
        "            'train_images': train_images_resized,\n",
        "            'train_labels': train_labels,\n",
        "            'test_images': test_images_resized,\n",
        "            'test_labels': test_labels,\n",
        "            'class_names': [str(i) for i in range(10)],\n",
        "            'dataset_type': 'grayscale'\n",
        "        }\n",
        "        \n",
        "        del train_images, test_images\n",
        "        gc.collect()\n",
        "        \n",
        "        print(f\"[OK] MNIST loaded: {len(train_images_resized)} train, {len(test_images_resized)} test\")\n",
        "        return mnist_data\n",
        "    \n",
        "    def load_cifar10(self):\n",
        "        \"\"\"Load and preprocess CIFAR-10 (color dataset)\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Loading CIFAR-10 Dataset\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        # Download dataset\n",
        "        trainset = torchvision.datasets.CIFAR10(\n",
        "            root=self.data_dir, train=True, download=True\n",
        "        )\n",
        "        testset = torchvision.datasets.CIFAR10(\n",
        "            root=self.data_dir, train=False, download=True\n",
        "        )\n",
        "        \n",
        "        # Convert to numpy in smaller batches\n",
        "        print(\"Converting training data...\")\n",
        "        train_images = []\n",
        "        train_labels = []\n",
        "        sub_batch_size = min(self.batch_size, 500)\n",
        "        \n",
        "        for i in range(0, len(trainset), sub_batch_size):\n",
        "            batch_end = min(i + sub_batch_size, len(trainset))\n",
        "            batch_imgs = [np.array(trainset[j][0]) for j in range(i, batch_end)]\n",
        "            batch_labels = [trainset[j][1] for j in range(i, batch_end)]\n",
        "            train_images.extend(batch_imgs)\n",
        "            train_labels.extend(batch_labels)\n",
        "            if i % (sub_batch_size * 10) == 0:\n",
        "                print(f\"  Processed {batch_end}/{len(trainset)} samples\")\n",
        "                self._check_memory_and_collect()\n",
        "        \n",
        "        print(\"Converting test data...\")\n",
        "        test_images = []\n",
        "        test_labels = []\n",
        "        for i in range(0, len(testset), sub_batch_size):\n",
        "            batch_end = min(i + sub_batch_size, len(testset))\n",
        "            batch_imgs = [np.array(testset[j][0]) for j in range(i, batch_end)]\n",
        "            batch_labels = [testset[j][1] for j in range(i, batch_end)]\n",
        "            test_images.extend(batch_imgs)\n",
        "            test_labels.extend(batch_labels)\n",
        "            if i % (sub_batch_size * 5) == 0:\n",
        "                self._check_memory_and_collect()\n",
        "        \n",
        "        train_images = np.array(train_images)\n",
        "        train_labels = np.array(train_labels)\n",
        "        test_images = np.array(test_images)\n",
        "        test_labels = np.array(test_labels)\n",
        "        \n",
        "        # Resize images\n",
        "        print(f\"Resizing to {self.img_size}...\")\n",
        "        train_images_resized = self.resize_images_batch(train_images, self.img_size)\n",
        "        del train_images\n",
        "        gc.collect()\n",
        "        \n",
        "        test_images_resized = self.resize_images_batch(test_images, self.img_size)\n",
        "        del test_images\n",
        "        gc.collect()\n",
        "        \n",
        "        # Normalize to [0, 1] range\n",
        "        train_images_resized = train_images_resized.astype('float32') / 255.0\n",
        "        test_images_resized = test_images_resized.astype('float32') / 255.0\n",
        "        \n",
        "        cifar_class_names = [\n",
        "            'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "            'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "        ]\n",
        "        \n",
        "        cifar_data = {\n",
        "            'train_images': train_images_resized,\n",
        "            'train_labels': train_labels,\n",
        "            'test_images': test_images_resized,\n",
        "            'test_labels': test_labels,\n",
        "            'class_names': cifar_class_names,\n",
        "            'dataset_type': 'color'\n",
        "        }\n",
        "        \n",
        "        gc.collect()\n",
        "        \n",
        "        print(f\"[OK] CIFAR-10 loaded: {len(train_images_resized)} train, {len(test_images_resized)} test\")\n",
        "        return cifar_data\n",
        "    \n",
        "    def save_datasets_separately(self, dataset_name, original_data, train_datasets, test_datasets):\n",
        "        \"\"\"Save datasets separately to avoid memory issues\"\"\"\n",
        "        print(f\"\\nSaving {dataset_name} datasets separately...\")\n",
        "        \n",
        "        # Save original data\n",
        "        original_path = os.path.join(self.processed_dir, f'{dataset_name}_original.pkl')\n",
        "        with open(original_path, 'wb') as f:\n",
        "            pickle.dump(original_data, f)\n",
        "        print(f\"[OK] Saved original data: {os.path.getsize(original_path) / (1024 * 1024):.2f} MB\")\n",
        "        \n",
        "        # Save training datasets\n",
        "        train_dir = os.path.join(self.processed_dir, f'{dataset_name}_train')\n",
        "        os.makedirs(train_dir, exist_ok=True)\n",
        "        \n",
        "        for train_type, data in train_datasets.items():\n",
        "            train_path = os.path.join(train_dir, f'{train_type}.pkl')\n",
        "            with open(train_path, 'wb') as f:\n",
        "                pickle.dump(data, f)\n",
        "            print(f\"[OK] Saved {train_type} train: {os.path.getsize(train_path) / (1024 * 1024):.2f} MB\")\n",
        "            gc.collect()\n",
        "        \n",
        "        # Save test datasets\n",
        "        test_dir = os.path.join(self.processed_dir, f'{dataset_name}_test')\n",
        "        os.makedirs(test_dir, exist_ok=True)\n",
        "        \n",
        "        for test_type, data in test_datasets.items():\n",
        "            test_path = os.path.join(test_dir, f'{test_type}.pkl')\n",
        "            with open(test_path, 'wb') as f:\n",
        "                pickle.dump(data, f)\n",
        "            print(f\"[OK] Saved {test_type} test: {os.path.getsize(test_path) / (1024 * 1024):.2f} MB\")\n",
        "            gc.collect()\n",
        "        \n",
        "        # Save metadata\n",
        "        metadata = {\n",
        "            'dataset_name': dataset_name,\n",
        "            'img_size': self.img_size,\n",
        "            'train_types': list(train_datasets.keys()),\n",
        "            'test_types': list(test_datasets.keys()),\n",
        "            'original_shape': original_data['train_images'].shape[1:]\n",
        "        }\n",
        "        \n",
        "        metadata_path = os.path.join(self.processed_dir, f'{dataset_name}_metadata.pkl')\n",
        "        with open(metadata_path, 'wb') as f:\n",
        "            pickle.dump(metadata, f)\n",
        "        \n",
        "        print(f\"[OK] Saved metadata\")\n",
        "        \n",
        "        # Clean up temp directories\n",
        "        import shutil\n",
        "        temp_train_dir = os.path.join(self.processed_dir, 'temp_train')\n",
        "        temp_test_dir = os.path.join(self.processed_dir, 'temp_test')\n",
        "        if os.path.exists(temp_train_dir):\n",
        "            shutil.rmtree(temp_train_dir)\n",
        "        if os.path.exists(temp_test_dir):\n",
        "            shutil.rmtree(temp_test_dir)\n",
        "    \n",
        "    def load_dataset(self, dataset_name, dataset_type, aug_type):\n",
        "        \"\"\"Load specific dataset\"\"\"\n",
        "        if dataset_type == 'original':\n",
        "            path = os.path.join(self.processed_dir, f'{dataset_name}_original.pkl')\n",
        "        elif dataset_type == 'train':\n",
        "            path = os.path.join(self.processed_dir, f'{dataset_name}_train', f'{aug_type}.pkl')\n",
        "        elif dataset_type == 'test':\n",
        "            path = os.path.join(self.processed_dir, f'{dataset_name}_test', f'{aug_type}.pkl')\n",
        "        \n",
        "        with open(path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        return data\n",
        "    \n",
        "    def visualize_augmentation_comparison(self, train_datasets, test_datasets, dataset_name, sample_idx=0):\n",
        "        \"\"\"Visualize training and test augmentations side by side\"\"\"\n",
        "        fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
        "        \n",
        "        # Training augmentations\n",
        "        train_types = ['original', 'mixed_augmented', 'combined_augmented']\n",
        "        train_titles = ['Original Train', 'Mixed Aug Train', 'Combined Aug Train']\n",
        "        \n",
        "        for i, (aug_type, title) in enumerate(zip(train_types, train_titles)):\n",
        "            img = train_datasets[aug_type]['images'][sample_idx]\n",
        "            if img.shape[-1] == 1:\n",
        "                axes[0, i].imshow(img.squeeze(), cmap='gray')\n",
        "            else:\n",
        "                axes[0, i].imshow(img)\n",
        "            axes[0, i].set_title(title, fontsize=10)\n",
        "            axes[0, i].axis('off')\n",
        "        \n",
        "        # Clear unused training plots\n",
        "        for i in range(3, 6):\n",
        "            axes[0, i].axis('off')\n",
        "        \n",
        "        # Test augmentations\n",
        "        test_types = ['original', 'rotation_15', 'noise', 'scaling_0.8', 'occlusion_25', 'all_combined']\n",
        "        test_titles = ['Original Test', 'Rotation 15°', 'Noise', 'Scaling 0.8x', 'Occlusion 25%', 'All Combined']\n",
        "        \n",
        "        for i, (aug_type, title) in enumerate(zip(test_types, test_titles)):\n",
        "            img = test_datasets[aug_type]['images'][sample_idx]\n",
        "            if img.shape[-1] == 1:\n",
        "                axes[1, i].imshow(img.squeeze(), cmap='gray')\n",
        "            else:\n",
        "                axes[1, i].imshow(img)\n",
        "            axes[1, i].set_title(title, fontsize=10)\n",
        "            axes[1, i].axis('off')\n",
        "        \n",
        "        plt.suptitle(f'{dataset_name} - Training and Test Augmentations', fontsize=14, y=1.02)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        save_path = os.path.join(self.processed_dir, f'{dataset_name}_augmentation_comparison.png')\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"[OK] Saved comparison to {save_path}\")\n",
        "        plt.close()\n",
        "        gc.collect()\n",
        "    \n",
        "    def print_dataset_statistics(self, train_datasets, test_datasets, dataset_name):\n",
        "        \"\"\"Print statistics for all datasets\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"{dataset_name.upper()} - Dataset Statistics\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        print(f\"\\nTRAINING SETS:\")\n",
        "        for aug_type in train_datasets.keys():\n",
        "            images = train_datasets[aug_type]['images']\n",
        "            labels = train_datasets[aug_type]['labels']\n",
        "            print(f\"  {aug_type.upper():<20}: {len(images):>6} samples, shape: {images[0].shape}\")\n",
        "        \n",
        "        print(f\"\\nTEST SETS:\")\n",
        "        for aug_type in test_datasets.keys():\n",
        "            images = test_datasets[aug_type]['images']\n",
        "            labels = test_datasets[aug_type]['labels']\n",
        "            print(f\"  {aug_type.upper():<20}: {len(images):>6} samples, shape: {images[0].shape}\")\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main preprocessing pipeline for robustness study\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ROBUSTNESS STUDY - DATASET PREPROCESSING\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Initialize preprocessor with adaptive memory management\n",
        "    preprocessor = DatasetPreprocessor(\n",
        "        data_dir='./data',\n",
        "        img_size=(128, 128),\n",
        "        batch_size=200\n",
        "    )\n",
        "    \n",
        "    try:\n",
        "        # ==========================================\n",
        "        # STEP 1: Collect Datasets\n",
        "        # ==========================================\n",
        "        \n",
        "        # Load MNIST (grayscale)\n",
        "        mnist_data = preprocessor.load_mnist()\n",
        "        \n",
        "        # ==========================================\n",
        "        # STEP 2: Create Augmented Datasets - MNIST\n",
        "        # ==========================================\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Creating Augmented Datasets for MNIST\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        mnist_train_datasets = preprocessor.create_augmented_train_set(\n",
        "            mnist_data['train_images'], \n",
        "            mnist_data['train_labels'],\n",
        "            mnist_data['class_names'],\n",
        "            'mnist'\n",
        "        )\n",
        "        mnist_test_datasets = preprocessor.create_augmented_test_sets(\n",
        "            mnist_data['test_images'], \n",
        "            mnist_data['test_labels'],\n",
        "            mnist_data['class_names'],\n",
        "            'mnist'\n",
        "        )\n",
        "        \n",
        "        # Save MNIST immediately to free memory\n",
        "        print(\"\\nSaving MNIST datasets...\")\n",
        "        preprocessor.save_datasets_separately('mnist', mnist_data, mnist_train_datasets, mnist_test_datasets)\n",
        "        \n",
        "        # Print MNIST statistics before freeing\n",
        "        preprocessor.print_dataset_statistics(mnist_train_datasets, mnist_test_datasets, 'MNIST')\n",
        "        \n",
        "        # Free MNIST memory\n",
        "        del mnist_data, mnist_train_datasets, mnist_test_datasets\n",
        "        gc.collect()\n",
        "        \n",
        "        \n",
        "        # ==========================================\n",
        "        # Visualizations (load small samples)\n",
        "        # ==========================================\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Creating Visualizations\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        # Load small samples for MNIST visualization\n",
        "        print(\"\\nCreating MNIST visualizations...\")\n",
        "        mnist_train_viz = {}\n",
        "        for train_type in ['original', 'mixed_augmented', 'combined_augmented']:\n",
        "            mnist_train_viz[train_type] = preprocessor.load_dataset('mnist', 'train', train_type)\n",
        "        \n",
        "        mnist_test_viz = {}\n",
        "        for test_type in ['original', 'rotation_15', 'noise', 'scaling_0.8', 'occlusion_25', 'all_combined']:\n",
        "            mnist_test_viz[test_type] = preprocessor.load_dataset('mnist', 'test', test_type)\n",
        "        \n",
        "        preprocessor.visualize_augmentation_comparison(mnist_train_viz, mnist_test_viz, 'MNIST')\n",
        "        \n",
        "        # Free MNIST visualization memory\n",
        "        del mnist_train_viz, mnist_test_viz\n",
        "        gc.collect()\n",
        "        \n",
        "        # ==========================================\n",
        "        # COMPLETION MESSAGE\n",
        "        # ==========================================\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"[OK] PREPROCESSING COMPLETE\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"\\nGenerated datasets for robustness study:\")\n",
        "        print(\"\\nTRAINING SETS (3 versions per dataset):\")\n",
        "        print(\"  1. original - Clean training data\")\n",
        "        print(\"  2. mixed_augmented - Equal parts: original + rotation + noise + scaling + occlusion\")\n",
        "        print(\"  3. combined_augmented - All augmentations applied to every sample\")\n",
        "        \n",
        "        print(\"\\nTEST SETS (6 versions per dataset):\")\n",
        "        print(\"  1. original - Clean test data\")\n",
        "        print(\"  2. rotation_15 - 15° rotation\")\n",
        "        print(\"  3. noise - Gaussian noise\")\n",
        "        print(\"  4. scaling_0.8 - 0.8x scaling\")\n",
        "        print(\"  5. occlusion_25 - 25% occlusion\")\n",
        "        print(\"  6. all_combined - All augmentations combined\")\n",
        "        \n",
        "        print(f\"\\nProcessed data saved in: {preprocessor.processed_dir}\")\n",
        "        print(f\"Sample images saved in: {preprocessor.samples_dir}\")\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        \n",
        "        return preprocessor\n",
        "        \n",
        "    except MemoryError as e:\n",
        "        print(f\"\\n[ERROR] Memory error occurred: {e}\")\n",
        "        print(\"Suggestions:\")\n",
        "        print(\"  1. Reduce img_size (e.g., to (96, 96) or (64, 64))\")\n",
        "        print(\"  2. Close other applications to free memory\")\n",
        "        print(\"  3. Process datasets one at a time by commenting out one dataset\")\n",
        "        print(\"  4. Increase system swap/virtual memory\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"\\n[ERROR] Error occurred: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "    finally:\n",
        "        # Final cleanup\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
