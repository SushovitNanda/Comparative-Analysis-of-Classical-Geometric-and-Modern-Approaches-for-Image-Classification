{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64ca2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "================================================================================\n",
      "PROCESSING DATASET: MNIST\n",
      "================================================================================\n",
      "\n",
      "\n",
      "************************************************************\n",
      "Training configuration: original\n",
      "************************************************************\n",
      "\n",
      "Loading: ./data/processed\\mnist_train\\original.pkl\n",
      "Training samples: 10000\n",
      "Image shape: (10000, 128, 128, 1)\n",
      "Label distribution: [1001 1127  991 1032  980  863 1014 1070  944  978]\n",
      "Train batches: 141, Val batches: 16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 141/141 [00:04<00:00, 32.41it/s, loss=0.0972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 0.1761, Train Acc: 95.23%, Val Acc: 98.30%, Val F1: 0.9829\n",
      "  ✓ New best validation F1: 0.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 141/141 [00:04<00:00, 34.94it/s, loss=0.0025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Loss: 0.0210, Train Acc: 99.53%, Val Acc: 99.00%, Val F1: 0.9896\n",
      "  ✓ New best validation F1: 0.9896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 141/141 [00:04<00:00, 34.96it/s, loss=0.0115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Loss: 0.0103, Train Acc: 99.72%, Val Acc: 98.80%, Val F1: 0.9879\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 141/141 [00:04<00:00, 33.14it/s, loss=0.0026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Loss: 0.0068, Train Acc: 99.82%, Val Acc: 98.50%, Val F1: 0.9851\n",
      "  No improvement (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 141/141 [00:04<00:00, 34.29it/s, loss=0.0281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Loss: 0.0067, Train Acc: 99.86%, Val Acc: 99.00%, Val F1: 0.9898\n",
      "  ✓ New best validation F1: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 141/141 [00:08<00:00, 16.52it/s, loss=0.0031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Loss: 0.0032, Train Acc: 99.94%, Val Acc: 98.70%, Val F1: 0.9868\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 141/141 [00:04<00:00, 33.24it/s, loss=0.0011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Loss: 0.0050, Train Acc: 99.88%, Val Acc: 98.40%, Val F1: 0.9840\n",
      "  No improvement (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 141/141 [00:04<00:00, 33.87it/s, loss=0.0014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Loss: 0.0116, Train Acc: 99.71%, Val Acc: 99.10%, Val F1: 0.9910\n",
      "  ✓ New best validation F1: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 141/141 [00:04<00:00, 34.82it/s, loss=0.0002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Loss: 0.0046, Train Acc: 99.89%, Val Acc: 98.80%, Val F1: 0.9877\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 141/141 [00:04<00:00, 34.62it/s, loss=0.0008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Loss: 0.0054, Train Acc: 99.88%, Val Acc: 99.10%, Val F1: 0.9906\n",
      "  No improvement (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 141/141 [00:04<00:00, 32.30it/s, loss=0.0003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Loss: 0.0018, Train Acc: 99.96%, Val Acc: 99.10%, Val F1: 0.9908\n",
      "  No improvement (3/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 141/141 [00:04<00:00, 34.60it/s, loss=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Loss: 0.0010, Train Acc: 99.99%, Val Acc: 99.10%, Val F1: 0.9906\n",
      "  No improvement (4/4)\n",
      "Early stopping triggered at epoch 12\n",
      "\n",
      "Loaded best model with Val F1: 0.9910\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: original\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\original.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9831    0.9943    0.9886       175\n",
      "           1     0.9957    1.0000    0.9979       234\n",
      "           2     0.9954    0.9863    0.9908       219\n",
      "           3     0.9904    0.9952    0.9928       207\n",
      "           4     0.9908    0.9908    0.9908       217\n",
      "           5     0.9943    0.9777    0.9859       179\n",
      "           6     0.9777    0.9831    0.9804       178\n",
      "           7     0.9854    0.9902    0.9878       205\n",
      "           8     0.9896    0.9948    0.9922       192\n",
      "           9     0.9896    0.9794    0.9845       194\n",
      "\n",
      "    accuracy                         0.9895      2000\n",
      "   macro avg     0.9892    0.9892    0.9892      2000\n",
      "weighted avg     0.9895    0.9895    0.9895      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 98.95%\n",
      "Test F1 Score: 0.9892\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: all_combined\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\all_combined.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9362    0.2514    0.3964       175\n",
      "           1     0.8571    0.5385    0.6614       234\n",
      "           2     0.3580    0.6849    0.4702       219\n",
      "           3     0.2014    0.9855    0.3344       207\n",
      "           4     1.0000    0.0046    0.0092       217\n",
      "           5     0.0000    0.0000    0.0000       179\n",
      "           6     0.9529    0.4551    0.6160       178\n",
      "           7     0.9394    0.1512    0.2605       205\n",
      "           8     0.6182    0.7083    0.6602       192\n",
      "           9     0.8824    0.1546    0.2632       194\n",
      "\n",
      "    accuracy                         0.4015      2000\n",
      "   macro avg     0.6746    0.3934    0.3671      2000\n",
      "weighted avg     0.6768    0.4015    0.3696      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 40.15%\n",
      "Test F1 Score: 0.3671\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: noise\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\noise.pkl\n",
      "Test samples: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0457    0.0874       175\n",
      "           1     0.0000    0.0000    0.0000       234\n",
      "           2     1.0000    0.0731    0.1362       219\n",
      "           3     0.1257    1.0000    0.2233       207\n",
      "           4     0.0000    0.0000    0.0000       217\n",
      "           5     0.0000    0.0000    0.0000       179\n",
      "           6     1.0000    0.0618    0.1164       178\n",
      "           7     0.0000    0.0000    0.0000       205\n",
      "           8     0.2799    0.4635    0.3490       192\n",
      "           9     0.0000    0.0000    0.0000       194\n",
      "\n",
      "    accuracy                         0.1655      2000\n",
      "   macro avg     0.3406    0.1644    0.0912      2000\n",
      "weighted avg     0.3259    0.1655    0.0895      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 16.55%\n",
      "Test F1 Score: 0.0912\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: occlusion_25\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\occlusion_25.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9454    0.9886    0.9665       175\n",
      "           1     0.9320    0.9957    0.9628       234\n",
      "           2     0.9765    0.9498    0.9630       219\n",
      "           3     0.8471    0.9903    0.9131       207\n",
      "           4     0.9275    0.8848    0.9057       217\n",
      "           5     0.9086    0.9441    0.9260       179\n",
      "           6     0.9701    0.9101    0.9391       178\n",
      "           7     0.8270    0.9561    0.8869       205\n",
      "           8     0.9822    0.8646    0.9197       192\n",
      "           9     0.9795    0.7371    0.8412       194\n",
      "\n",
      "    accuracy                         0.9235      2000\n",
      "   macro avg     0.9296    0.9221    0.9224      2000\n",
      "weighted avg     0.9287    0.9235    0.9227      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 92.35%\n",
      "Test F1 Score: 0.9224\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: rotation_15\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\rotation_15.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9667    0.9943    0.9803       175\n",
      "           1     0.9708    0.9957    0.9831       234\n",
      "           2     0.9857    0.9452    0.9650       219\n",
      "           3     0.9950    0.9662    0.9804       207\n",
      "           4     0.9860    0.9770    0.9815       217\n",
      "           5     0.9827    0.9497    0.9659       179\n",
      "           6     0.9613    0.9775    0.9694       178\n",
      "           7     0.9434    0.9756    0.9592       205\n",
      "           8     0.9896    0.9948    0.9922       192\n",
      "           9     0.9744    0.9794    0.9769       194\n",
      "\n",
      "    accuracy                         0.9755      2000\n",
      "   macro avg     0.9756    0.9755    0.9754      2000\n",
      "weighted avg     0.9758    0.9755    0.9755      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 97.55%\n",
      "Test F1 Score: 0.9754\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: scaling_0.8\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\scaling_0.8.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9886    0.9943    0.9915       175\n",
      "           1     0.9957    0.9957    0.9957       234\n",
      "           2     0.9908    0.9817    0.9862       219\n",
      "           3     0.9904    0.9952    0.9928       207\n",
      "           4     0.9904    0.9539    0.9718       217\n",
      "           5     1.0000    0.9777    0.9887       179\n",
      "           6     0.9887    0.9831    0.9859       178\n",
      "           7     0.9760    0.9902    0.9831       205\n",
      "           8     0.9409    0.9948    0.9671       192\n",
      "           9     0.9741    0.9691    0.9716       194\n",
      "\n",
      "    accuracy                         0.9835      2000\n",
      "   macro avg     0.9836    0.9836    0.9834      2000\n",
      "weighted avg     0.9838    0.9835    0.9835      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 98.35%\n",
      "Test F1 Score: 0.9834\n",
      "\n",
      "✓ Completed training configuration: original\n",
      "\n",
      "\n",
      "************************************************************\n",
      "Training configuration: mixed_augmented\n",
      "************************************************************\n",
      "\n",
      "Loading: ./data/processed\\mnist_train\\mixed_augmented.pkl\n",
      "Training samples: 10000\n",
      "Image shape: (10000, 128, 128, 1)\n",
      "Label distribution: [1004 1083 1021 1006  997  893  957 1049 1018  972]\n",
      "Train batches: 141, Val batches: 16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 141/141 [00:04<00:00, 33.32it/s, loss=0.0577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 0.1755, Train Acc: 95.24%, Val Acc: 98.20%, Val F1: 0.9817\n",
      "  ✓ New best validation F1: 0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 141/141 [00:04<00:00, 34.41it/s, loss=0.0143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Loss: 0.0190, Train Acc: 99.47%, Val Acc: 98.80%, Val F1: 0.9879\n",
      "  ✓ New best validation F1: 0.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 141/141 [00:04<00:00, 34.84it/s, loss=0.0005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Loss: 0.0076, Train Acc: 99.83%, Val Acc: 98.60%, Val F1: 0.9863\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 141/141 [00:04<00:00, 34.28it/s, loss=0.0012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Loss: 0.0068, Train Acc: 99.82%, Val Acc: 99.10%, Val F1: 0.9910\n",
      "  ✓ New best validation F1: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 141/141 [00:04<00:00, 34.47it/s, loss=0.0041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Loss: 0.0037, Train Acc: 99.92%, Val Acc: 98.50%, Val F1: 0.9845\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 141/141 [00:04<00:00, 35.04it/s, loss=0.0021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Loss: 0.0058, Train Acc: 99.87%, Val Acc: 98.90%, Val F1: 0.9888\n",
      "  No improvement (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 141/141 [00:04<00:00, 34.68it/s, loss=0.0024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Loss: 0.0111, Train Acc: 99.59%, Val Acc: 98.00%, Val F1: 0.9802\n",
      "  No improvement (3/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 141/141 [00:04<00:00, 34.43it/s, loss=0.0022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Loss: 0.0109, Train Acc: 99.68%, Val Acc: 98.60%, Val F1: 0.9861\n",
      "  No improvement (4/4)\n",
      "Early stopping triggered at epoch 8\n",
      "\n",
      "Loaded best model with Val F1: 0.9910\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: original\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\original.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9943    0.9943    0.9943       175\n",
      "           1     0.9791    1.0000    0.9894       234\n",
      "           2     0.9907    0.9680    0.9792       219\n",
      "           3     0.9951    0.9807    0.9878       207\n",
      "           4     0.9772    0.9862    0.9817       217\n",
      "           5     0.9833    0.9888    0.9861       179\n",
      "           6     0.9944    0.9888    0.9915       178\n",
      "           7     0.9619    0.9854    0.9735       205\n",
      "           8     0.9947    0.9792    0.9869       192\n",
      "           9     0.9845    0.9794    0.9819       194\n",
      "\n",
      "    accuracy                         0.9850      2000\n",
      "   macro avg     0.9855    0.9851    0.9852      2000\n",
      "weighted avg     0.9851    0.9850    0.9850      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 98.50%\n",
      "Test F1 Score: 0.9852\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: all_combined\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\all_combined.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8387    0.5943    0.6957       175\n",
      "           1     0.2359    1.0000    0.3817       234\n",
      "           2     0.3889    0.4475    0.4161       219\n",
      "           3     0.7239    0.4686    0.5689       207\n",
      "           4     0.9333    0.0645    0.1207       217\n",
      "           5     0.8889    0.1788    0.2977       179\n",
      "           6     0.9348    0.2416    0.3839       178\n",
      "           7     1.0000    0.0439    0.0841       205\n",
      "           8     0.4175    0.8438    0.5586       192\n",
      "           9     1.0000    0.0206    0.0404       194\n",
      "\n",
      "    accuracy                         0.3985      2000\n",
      "   macro avg     0.7362    0.3904    0.3548      2000\n",
      "weighted avg     0.7221    0.3985    0.3501      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 39.85%\n",
      "Test F1 Score: 0.3548\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: noise\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\noise.pkl\n",
      "Test samples: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6303    0.5943    0.6118       175\n",
      "           1     0.2812    1.0000    0.4390       234\n",
      "           2     1.0000    0.0091    0.0181       219\n",
      "           3     0.0000    0.0000    0.0000       207\n",
      "           4     0.0000    0.0000    0.0000       217\n",
      "           5     0.0000    0.0000    0.0000       179\n",
      "           6     0.0000    0.0000    0.0000       178\n",
      "           7     0.0000    0.0000    0.0000       205\n",
      "           8     0.1888    0.9844    0.3168       192\n",
      "           9     0.0000    0.0000    0.0000       194\n",
      "\n",
      "    accuracy                         0.2645      2000\n",
      "   macro avg     0.2100    0.2588    0.1386      2000\n",
      "weighted avg     0.2157    0.2645    0.1373      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 26.45%\n",
      "Test F1 Score: 0.1386\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: occlusion_25\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\occlusion_25.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9261    0.9314    0.9288       175\n",
      "           1     0.7774    1.0000    0.8748       234\n",
      "           2     0.9469    0.8950    0.9202       219\n",
      "           3     0.9190    0.9324    0.9257       207\n",
      "           4     0.8710    0.8710    0.8710       217\n",
      "           5     0.8866    0.9609    0.9223       179\n",
      "           6     0.9708    0.9326    0.9513       178\n",
      "           7     0.8084    0.8439    0.8258       205\n",
      "           8     0.9471    0.8385    0.8895       192\n",
      "           9     0.9643    0.6959    0.8084       194\n",
      "\n",
      "    accuracy                         0.8910      2000\n",
      "   macro avg     0.9018    0.8902    0.8918      2000\n",
      "weighted avg     0.8984    0.8910    0.8903      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 89.10%\n",
      "Test F1 Score: 0.8918\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: rotation_15\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\rotation_15.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8788    0.9943    0.9330       175\n",
      "           1     0.9000    1.0000    0.9474       234\n",
      "           2     0.9798    0.8858    0.9305       219\n",
      "           3     1.0000    0.8986    0.9466       207\n",
      "           4     0.9640    0.9862    0.9749       217\n",
      "           5     0.9771    0.9553    0.9661       179\n",
      "           6     0.9609    0.9663    0.9636       178\n",
      "           7     0.8660    0.8829    0.8744       205\n",
      "           8     0.9945    0.9427    0.9679       192\n",
      "           9     0.9686    0.9536    0.9610       194\n",
      "\n",
      "    accuracy                         0.9460      2000\n",
      "   macro avg     0.9490    0.9466    0.9465      2000\n",
      "weighted avg     0.9487    0.9460    0.9461      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 94.60%\n",
      "Test F1 Score: 0.9465\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: scaling_0.8\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\scaling_0.8.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9486    0.9736       175\n",
      "           1     0.9630    1.0000    0.9811       234\n",
      "           2     0.9863    0.9863    0.9863       219\n",
      "           3     0.9902    0.9807    0.9854       207\n",
      "           4     0.9772    0.9862    0.9817       217\n",
      "           5     0.9833    0.9888    0.9861       179\n",
      "           6     0.9415    0.9944    0.9672       178\n",
      "           7     0.9847    0.9415    0.9626       205\n",
      "           8     0.9894    0.9688    0.9789       192\n",
      "           9     0.9796    0.9897    0.9846       194\n",
      "\n",
      "    accuracy                         0.9790      2000\n",
      "   macro avg     0.9795    0.9785    0.9788      2000\n",
      "weighted avg     0.9794    0.9790    0.9790      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 97.90%\n",
      "Test F1 Score: 0.9788\n",
      "\n",
      "✓ Completed training configuration: mixed_augmented\n",
      "\n",
      "\n",
      "************************************************************\n",
      "Training configuration: combined_augmented\n",
      "************************************************************\n",
      "\n",
      "Loading: ./data/processed\\mnist_train\\combined_augmented.pkl\n",
      "Training samples: 10000\n",
      "Image shape: (10000, 128, 128, 1)\n",
      "Label distribution: [1001 1127  991 1032  980  863 1014 1070  944  978]\n",
      "Train batches: 141, Val batches: 16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 141/141 [00:04<00:00, 33.38it/s, loss=0.2667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 0.3383, Train Acc: 90.03%, Val Acc: 97.20%, Val F1: 0.9715\n",
      "  ✓ New best validation F1: 0.9715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 141/141 [00:04<00:00, 34.95it/s, loss=0.1051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Loss: 0.0447, Train Acc: 98.76%, Val Acc: 97.20%, Val F1: 0.9718\n",
      "  ✓ New best validation F1: 0.9718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 141/141 [00:04<00:00, 35.06it/s, loss=0.0040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Loss: 0.0161, Train Acc: 99.59%, Val Acc: 97.60%, Val F1: 0.9750\n",
      "  ✓ New best validation F1: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 141/141 [00:04<00:00, 34.46it/s, loss=0.0117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Loss: 0.0075, Train Acc: 99.87%, Val Acc: 97.40%, Val F1: 0.9736\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 141/141 [00:04<00:00, 34.66it/s, loss=0.0028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Loss: 0.0083, Train Acc: 99.77%, Val Acc: 97.20%, Val F1: 0.9714\n",
      "  No improvement (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 141/141 [00:03<00:00, 35.54it/s, loss=0.0010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Loss: 0.0088, Train Acc: 99.83%, Val Acc: 97.40%, Val F1: 0.9735\n",
      "  No improvement (3/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 141/141 [00:04<00:00, 35.07it/s, loss=0.0009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Loss: 0.0051, Train Acc: 99.90%, Val Acc: 96.30%, Val F1: 0.9625\n",
      "  No improvement (4/4)\n",
      "Early stopping triggered at epoch 7\n",
      "\n",
      "Loaded best model with Val F1: 0.9750\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: original\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\original.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9162    1.0000    0.9563       175\n",
      "           1     0.9912    0.9573    0.9739       234\n",
      "           2     0.9945    0.8219    0.9000       219\n",
      "           3     1.0000    0.8599    0.9247       207\n",
      "           4     0.9791    0.8618    0.9167       217\n",
      "           5     0.8693    0.9665    0.9153       179\n",
      "           6     0.9545    0.9438    0.9492       178\n",
      "           7     0.8904    0.9902    0.9376       205\n",
      "           8     0.6971    0.9948    0.8197       192\n",
      "           9     0.9808    0.7887    0.8743       194\n",
      "\n",
      "    accuracy                         0.9160      2000\n",
      "   macro avg     0.9273    0.9185    0.9168      2000\n",
      "weighted avg     0.9308    0.9160    0.9173      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 91.60%\n",
      "Test F1 Score: 0.9168\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: all_combined\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\all_combined.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9829    0.9829    0.9829       175\n",
      "           1     0.9914    0.9872    0.9893       234\n",
      "           2     0.9952    0.9452    0.9696       219\n",
      "           3     0.9801    0.9517    0.9657       207\n",
      "           4     0.9614    0.9171    0.9387       217\n",
      "           5     0.9036    0.9944    0.9468       179\n",
      "           6     0.9828    0.9607    0.9716       178\n",
      "           7     0.9312    0.9902    0.9598       205\n",
      "           8     0.9844    0.9844    0.9844       192\n",
      "           9     0.9333    0.9381    0.9357       194\n",
      "\n",
      "    accuracy                         0.9645      2000\n",
      "   macro avg     0.9646    0.9652    0.9644      2000\n",
      "weighted avg     0.9655    0.9645    0.9646      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 96.45%\n",
      "Test F1 Score: 0.9644\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: noise\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\noise.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9560    0.9943    0.9748       175\n",
      "           1     0.9870    0.9744    0.9806       234\n",
      "           2     0.9861    0.6484    0.7824       219\n",
      "           3     0.8899    0.9372    0.9129       207\n",
      "           4     1.0000    0.7281    0.8427       217\n",
      "           5     0.5280    1.0000    0.6911       179\n",
      "           6     0.9863    0.8090    0.8889       178\n",
      "           7     0.9029    0.9073    0.9051       205\n",
      "           8     0.9465    0.9219    0.9340       192\n",
      "           9     0.9259    0.9021    0.9138       194\n",
      "\n",
      "    accuracy                         0.8785      2000\n",
      "   macro avg     0.9109    0.8823    0.8826      2000\n",
      "weighted avg     0.9160    0.8785    0.8837      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 87.85%\n",
      "Test F1 Score: 0.8826\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: occlusion_25\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\occlusion_25.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9255    0.9943    0.9587       175\n",
      "           1     0.9860    0.9060    0.9443       234\n",
      "           2     0.9874    0.7169    0.8307       219\n",
      "           3     0.9886    0.8357    0.9058       207\n",
      "           4     0.9286    0.8387    0.8814       217\n",
      "           5     0.8442    0.9385    0.8889       179\n",
      "           6     0.9467    0.8989    0.9222       178\n",
      "           7     0.7731    0.9805    0.8645       205\n",
      "           8     0.6429    0.9844    0.7778       192\n",
      "           9     0.9586    0.7165    0.8201       194\n",
      "\n",
      "    accuracy                         0.8775      2000\n",
      "   macro avg     0.8982    0.8810    0.8794      2000\n",
      "weighted avg     0.9013    0.8775    0.8792      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 87.75%\n",
      "Test F1 Score: 0.8794\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: rotation_15\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\rotation_15.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9511    1.0000    0.9749       175\n",
      "           1     1.0000    0.9145    0.9554       234\n",
      "           2     1.0000    0.9087    0.9522       219\n",
      "           3     1.0000    0.9227    0.9598       207\n",
      "           4     0.9381    0.9770    0.9571       217\n",
      "           5     0.9082    0.9944    0.9493       179\n",
      "           6     0.9560    0.9775    0.9667       178\n",
      "           7     0.9186    0.9902    0.9531       205\n",
      "           8     0.9057    1.0000    0.9505       192\n",
      "           9     0.9943    0.8969    0.9431       194\n",
      "\n",
      "    accuracy                         0.9560      2000\n",
      "   macro avg     0.9572    0.9582    0.9562      2000\n",
      "weighted avg     0.9589    0.9560    0.9559      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 95.60%\n",
      "Test F1 Score: 0.9562\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: scaling_0.8\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\mnist_test\\scaling_0.8.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9669    1.0000    0.9831       175\n",
      "           1     1.0000    0.9573    0.9782       234\n",
      "           2     0.9659    0.9041    0.9340       219\n",
      "           3     1.0000    0.8261    0.9048       207\n",
      "           4     0.9825    0.7742    0.8660       217\n",
      "           5     0.9497    0.9497    0.9497       179\n",
      "           6     0.9820    0.9213    0.9507       178\n",
      "           7     0.9466    0.9512    0.9489       205\n",
      "           8     0.6057    1.0000    0.7544       192\n",
      "           9     0.8883    0.8196    0.8525       194\n",
      "\n",
      "    accuracy                         0.9080      2000\n",
      "   macro avg     0.9287    0.9104    0.9122      2000\n",
      "weighted avg     0.9312    0.9080    0.9123      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 90.80%\n",
      "Test F1 Score: 0.9122\n",
      "\n",
      "✓ Completed training configuration: combined_augmented\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PROCESSING DATASET: CIFAR10\n",
      "================================================================================\n",
      "\n",
      "\n",
      "************************************************************\n",
      "Training configuration: original\n",
      "************************************************************\n",
      "\n",
      "Loading: ./data/processed\\cifar10_train\\original.pkl\n",
      "Training samples: 10000\n",
      "Image shape: (10000, 128, 128, 3)\n",
      "Label distribution: [1005  974 1032 1016  999  937 1030 1001 1025  981]\n",
      "Train batches: 141, Val batches: 16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 141/141 [00:04<00:00, 32.03it/s, loss=0.6038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 0.6546, Train Acc: 78.83%, Val Acc: 89.40%, Val F1: 0.8919\n",
      "  ✓ New best validation F1: 0.8919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 141/141 [00:04<00:00, 33.94it/s, loss=0.1954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Loss: 0.1255, Train Acc: 96.59%, Val Acc: 89.20%, Val F1: 0.8907\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 141/141 [00:04<00:00, 34.77it/s, loss=0.0276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Loss: 0.0309, Train Acc: 99.58%, Val Acc: 91.10%, Val F1: 0.9096\n",
      "  ✓ New best validation F1: 0.9096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 141/141 [00:04<00:00, 31.69it/s, loss=0.0132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Loss: 0.0111, Train Acc: 99.94%, Val Acc: 91.50%, Val F1: 0.9140\n",
      "  ✓ New best validation F1: 0.9140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 141/141 [00:04<00:00, 33.06it/s, loss=0.0040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Loss: 0.0056, Train Acc: 99.97%, Val Acc: 91.90%, Val F1: 0.9175\n",
      "  ✓ New best validation F1: 0.9175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 141/141 [00:07<00:00, 18.17it/s, loss=0.0018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Loss: 0.0038, Train Acc: 99.99%, Val Acc: 91.80%, Val F1: 0.9170\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 141/141 [00:08<00:00, 17.08it/s, loss=0.0073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Loss: 0.0023, Train Acc: 100.00%, Val Acc: 92.30%, Val F1: 0.9218\n",
      "  ✓ New best validation F1: 0.9218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 141/141 [00:09<00:00, 14.26it/s, loss=0.0010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Loss: 0.0021, Train Acc: 100.00%, Val Acc: 92.40%, Val F1: 0.9230\n",
      "  ✓ New best validation F1: 0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 141/141 [00:08<00:00, 15.97it/s, loss=0.0017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Loss: 0.0022, Train Acc: 99.99%, Val Acc: 92.50%, Val F1: 0.9238\n",
      "  ✓ New best validation F1: 0.9238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 141/141 [00:09<00:00, 15.65it/s, loss=0.0018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Loss: 0.0014, Train Acc: 100.00%, Val Acc: 92.50%, Val F1: 0.9241\n",
      "  ✓ New best validation F1: 0.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 141/141 [00:10<00:00, 13.82it/s, loss=0.0007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Loss: 0.0010, Train Acc: 100.00%, Val Acc: 92.60%, Val F1: 0.9248\n",
      "  ✓ New best validation F1: 0.9248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 141/141 [00:08<00:00, 16.90it/s, loss=0.0006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Loss: 0.0010, Train Acc: 100.00%, Val Acc: 92.30%, Val F1: 0.9219\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 141/141 [00:08<00:00, 16.85it/s, loss=0.0009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Loss: 0.0008, Train Acc: 100.00%, Val Acc: 92.50%, Val F1: 0.9242\n",
      "  No improvement (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 141/141 [00:05<00:00, 27.37it/s, loss=0.0007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Loss: 0.0025, Train Acc: 99.96%, Val Acc: 90.50%, Val F1: 0.9034\n",
      "  No improvement (3/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 141/141 [00:04<00:00, 33.49it/s, loss=0.1814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Loss: 0.2090, Train Acc: 93.40%, Val Acc: 86.50%, Val F1: 0.8637\n",
      "  No improvement (4/4)\n",
      "Early stopping triggered at epoch 15\n",
      "\n",
      "Loaded best model with Val F1: 0.9248\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: original\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\original.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7788    0.8980    0.8341       196\n",
      "           1     0.8383    0.9949    0.9099       198\n",
      "           2     0.7436    0.8923    0.8112       195\n",
      "           3     0.7358    0.7839    0.7591       199\n",
      "           4     0.9119    0.8889    0.9003       198\n",
      "           5     0.8921    0.6703    0.7654       185\n",
      "           6     0.9447    0.8704    0.9060       216\n",
      "           7     0.8812    0.9223    0.9013       193\n",
      "           8     0.9479    0.8387    0.8900       217\n",
      "           9     0.9821    0.8128    0.8895       203\n",
      "\n",
      "    accuracy                         0.8580      2000\n",
      "   macro avg     0.8656    0.8572    0.8567      2000\n",
      "weighted avg     0.8674    0.8580    0.8580      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 85.80%\n",
      "Test F1 Score: 0.8567\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: all_combined\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\all_combined.pkl\n",
      "Test samples: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1070    1.0000    0.1933       196\n",
      "           1     0.8421    0.0808    0.1475       198\n",
      "           2     0.2031    0.0667    0.1004       195\n",
      "           3     0.3750    0.0151    0.0290       199\n",
      "           4     0.0000    0.0000    0.0000       198\n",
      "           5     1.0000    0.0054    0.0108       185\n",
      "           6     0.5526    0.1944    0.2877       216\n",
      "           7     0.0000    0.0000    0.0000       193\n",
      "           8     0.0000    0.0000    0.0000       217\n",
      "           9     0.0000    0.0000    0.0000       203\n",
      "\n",
      "    accuracy                         0.1355      2000\n",
      "   macro avg     0.3080    0.1362    0.0769      2000\n",
      "weighted avg     0.3032    0.1355    0.0783      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 13.55%\n",
      "Test F1 Score: 0.0769\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: noise\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\noise.pkl\n",
      "Test samples: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1148    0.9745    0.2054       196\n",
      "           1     0.9000    0.0909    0.1651       198\n",
      "           2     0.2730    0.4103    0.3279       195\n",
      "           3     0.0000    0.0000    0.0000       199\n",
      "           4     0.3750    0.0152    0.0291       198\n",
      "           5     0.0000    0.0000    0.0000       185\n",
      "           6     0.8000    0.0370    0.0708       216\n",
      "           7     1.0000    0.0155    0.0306       193\n",
      "           8     1.0000    0.0046    0.0092       217\n",
      "           9     1.0000    0.0049    0.0098       203\n",
      "\n",
      "    accuracy                         0.1525      2000\n",
      "   macro avg     0.5463    0.1553    0.0848      2000\n",
      "weighted avg     0.5570    0.1525    0.0839      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 15.25%\n",
      "Test F1 Score: 0.0848\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: occlusion_25\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\occlusion_25.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5376    0.9490    0.6863       196\n",
      "           1     0.8578    0.8838    0.8706       198\n",
      "           2     0.5753    0.7641    0.6564       195\n",
      "           3     0.5683    0.7940    0.6625       199\n",
      "           4     0.8263    0.7929    0.8093       198\n",
      "           5     0.8710    0.4378    0.5827       185\n",
      "           6     0.9846    0.5926    0.7399       216\n",
      "           7     0.9276    0.7306    0.8174       193\n",
      "           8     0.8272    0.7281    0.7745       217\n",
      "           9     0.9427    0.7291    0.8222       203\n",
      "\n",
      "    accuracy                         0.7405      2000\n",
      "   macro avg     0.7918    0.7402    0.7422      2000\n",
      "weighted avg     0.7939    0.7405    0.7437      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 74.05%\n",
      "Test F1 Score: 0.7422\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: rotation_15\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\rotation_15.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2774    0.9541    0.4299       196\n",
      "           1     0.7231    0.7121    0.7176       198\n",
      "           2     0.4231    0.7333    0.5366       195\n",
      "           3     0.5263    0.6533    0.5830       199\n",
      "           4     0.8065    0.2525    0.3846       198\n",
      "           5     0.8081    0.4324    0.5634       185\n",
      "           6     0.8491    0.6250    0.7200       216\n",
      "           7     0.9672    0.3057    0.4646       193\n",
      "           8     0.8033    0.4516    0.5782       217\n",
      "           9     0.9302    0.1970    0.3252       203\n",
      "\n",
      "    accuracy                         0.5315      2000\n",
      "   macro avg     0.7114    0.5317    0.5303      2000\n",
      "weighted avg     0.7136    0.5315    0.5320      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 53.15%\n",
      "Test F1 Score: 0.5303\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: scaling_0.8\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\scaling_0.8.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5095    0.8214    0.6289       196\n",
      "           1     0.7265    0.8990    0.8036       198\n",
      "           2     0.3986    0.8667    0.5460       195\n",
      "           3     0.6437    0.5628    0.6005       199\n",
      "           4     0.7239    0.4899    0.5843       198\n",
      "           5     0.8434    0.3784    0.5224       185\n",
      "           6     0.6139    0.8981    0.7293       216\n",
      "           7     0.9027    0.5285    0.6667       193\n",
      "           8     0.8772    0.4608    0.6042       217\n",
      "           9     1.0000    0.3990    0.5704       203\n",
      "\n",
      "    accuracy                         0.6320      2000\n",
      "   macro avg     0.7239    0.6305    0.6256      2000\n",
      "weighted avg     0.7245    0.6320    0.6269      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 63.20%\n",
      "Test F1 Score: 0.6256\n",
      "\n",
      "✓ Completed training configuration: original\n",
      "\n",
      "\n",
      "************************************************************\n",
      "Training configuration: mixed_augmented\n",
      "************************************************************\n",
      "\n",
      "Loading: ./data/processed\\cifar10_train\\mixed_augmented.pkl\n",
      "Training samples: 10000\n",
      "Image shape: (10000, 128, 128, 3)\n",
      "Label distribution: [1023  997 1010  996  951  983 1036 1032 1013  959]\n",
      "Train batches: 141, Val batches: 16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 141/141 [00:07<00:00, 19.75it/s, loss=0.4312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 0.6697, Train Acc: 77.79%, Val Acc: 86.30%, Val F1: 0.8638\n",
      "  ✓ New best validation F1: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 141/141 [00:10<00:00, 13.86it/s, loss=0.1295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Loss: 0.1296, Train Acc: 96.36%, Val Acc: 88.80%, Val F1: 0.8871\n",
      "  ✓ New best validation F1: 0.8871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 141/141 [00:09<00:00, 15.39it/s, loss=0.0145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Loss: 0.0320, Train Acc: 99.61%, Val Acc: 89.90%, Val F1: 0.8985\n",
      "  ✓ New best validation F1: 0.8985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 141/141 [00:08<00:00, 16.39it/s, loss=0.0235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Loss: 0.0107, Train Acc: 99.93%, Val Acc: 89.50%, Val F1: 0.8946\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 141/141 [00:08<00:00, 15.76it/s, loss=0.0235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Loss: 0.0072, Train Acc: 99.94%, Val Acc: 90.40%, Val F1: 0.9034\n",
      "  ✓ New best validation F1: 0.9034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 141/141 [00:07<00:00, 20.05it/s, loss=0.0085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Loss: 0.0037, Train Acc: 100.00%, Val Acc: 89.80%, Val F1: 0.8980\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 141/141 [00:04<00:00, 32.23it/s, loss=0.0046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Loss: 0.0032, Train Acc: 99.99%, Val Acc: 87.10%, Val F1: 0.8700\n",
      "  No improvement (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 141/141 [00:04<00:00, 34.66it/s, loss=0.0076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Loss: 0.0132, Train Acc: 99.69%, Val Acc: 87.80%, Val F1: 0.8773\n",
      "  No improvement (3/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 141/141 [00:04<00:00, 33.56it/s, loss=0.0857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Loss: 0.0240, Train Acc: 99.36%, Val Acc: 87.30%, Val F1: 0.8732\n",
      "  No improvement (4/4)\n",
      "Early stopping triggered at epoch 9\n",
      "\n",
      "Loaded best model with Val F1: 0.9034\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: original\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\original.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9116    0.8418    0.8753       196\n",
      "           1     0.9534    0.9293    0.9412       198\n",
      "           2     0.8272    0.8103    0.8187       195\n",
      "           3     0.6654    0.9095    0.7686       199\n",
      "           4     0.8284    0.8535    0.8408       198\n",
      "           5     0.8485    0.7568    0.8000       185\n",
      "           6     0.9192    0.8426    0.8792       216\n",
      "           7     0.9405    0.8187    0.8753       193\n",
      "           8     0.9079    0.9539    0.9303       217\n",
      "           9     0.9400    0.9261    0.9330       203\n",
      "\n",
      "    accuracy                         0.8660      2000\n",
      "   macro avg     0.8742    0.8642    0.8662      2000\n",
      "weighted avg     0.8750    0.8660    0.8676      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 86.60%\n",
      "Test F1 Score: 0.8662\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: all_combined\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\all_combined.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1887    0.8724    0.3103       196\n",
      "           1     0.7742    0.1212    0.2096       198\n",
      "           2     0.1842    0.1077    0.1359       195\n",
      "           3     0.2099    0.4673    0.2897       199\n",
      "           4     0.2013    0.3182    0.2466       198\n",
      "           5     0.5600    0.0757    0.1333       185\n",
      "           6     0.4512    0.1713    0.2483       216\n",
      "           7     0.4865    0.0933    0.1565       193\n",
      "           8     0.6250    0.0461    0.0858       217\n",
      "           9     0.3333    0.0542    0.0932       203\n",
      "\n",
      "    accuracy                         0.2310      2000\n",
      "   macro avg     0.4014    0.2327    0.1909      2000\n",
      "weighted avg     0.4030    0.2310    0.1907      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 23.10%\n",
      "Test F1 Score: 0.1909\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: noise\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\noise.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2500    0.8622    0.3876       196\n",
      "           1     0.8824    0.3788    0.5300       198\n",
      "           2     0.2561    0.4821    0.3345       195\n",
      "           3     0.4062    0.2613    0.3180       199\n",
      "           4     0.6087    0.0707    0.1267       198\n",
      "           5     0.6757    0.1351    0.2252       185\n",
      "           6     0.6842    0.1204    0.2047       216\n",
      "           7     0.8889    0.2902    0.4375       193\n",
      "           8     0.2410    0.6175    0.3467       217\n",
      "           9     0.9259    0.1232    0.2174       203\n",
      "\n",
      "    accuracy                         0.3350      2000\n",
      "   macro avg     0.5819    0.3341    0.3128      2000\n",
      "weighted avg     0.5798    0.3350    0.3121      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 33.50%\n",
      "Test F1 Score: 0.3128\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: occlusion_25\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\occlusion_25.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8011    0.7398    0.7692       196\n",
      "           1     0.9390    0.7778    0.8508       198\n",
      "           2     0.6128    0.7385    0.6698       195\n",
      "           3     0.3559    0.9497    0.5178       199\n",
      "           4     0.7821    0.6162    0.6893       198\n",
      "           5     0.8411    0.4865    0.6164       185\n",
      "           6     0.9592    0.4352    0.5987       216\n",
      "           7     0.9091    0.6218    0.7385       193\n",
      "           8     0.9058    0.7972    0.8480       217\n",
      "           9     0.8244    0.8325    0.8284       203\n",
      "\n",
      "    accuracy                         0.7000      2000\n",
      "   macro avg     0.7930    0.6995    0.7127      2000\n",
      "weighted avg     0.7951    0.7000    0.7137      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 70.00%\n",
      "Test F1 Score: 0.7127\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: rotation_15\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\rotation_15.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4199    0.7092    0.5275       196\n",
      "           1     0.9275    0.3232    0.4794       198\n",
      "           2     0.4731    0.6769    0.5570       195\n",
      "           3     0.4190    0.8191    0.5544       199\n",
      "           4     0.8387    0.1313    0.2271       198\n",
      "           5     0.5907    0.6865    0.6350       185\n",
      "           6     0.9672    0.5463    0.6982       216\n",
      "           7     0.9623    0.2642    0.4146       193\n",
      "           8     0.4406    0.9401    0.6000       217\n",
      "           9     0.9167    0.2167    0.3506       203\n",
      "\n",
      "    accuracy                         0.5340      2000\n",
      "   macro avg     0.6956    0.5314    0.5044      2000\n",
      "weighted avg     0.6966    0.5340    0.5059      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 53.40%\n",
      "Test F1 Score: 0.5044\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: scaling_0.8\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\scaling_0.8.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6933    0.7959    0.7411       196\n",
      "           1     0.9184    0.6818    0.7826       198\n",
      "           2     0.7333    0.7333    0.7333       195\n",
      "           3     0.4355    0.8995    0.5869       199\n",
      "           4     0.9341    0.4293    0.5882       198\n",
      "           5     0.9362    0.4757    0.6308       185\n",
      "           6     0.7635    0.8519    0.8053       216\n",
      "           7     0.6117    0.8653    0.7167       193\n",
      "           8     0.7814    0.7742    0.7778       217\n",
      "           9     0.9722    0.5172    0.6752       203\n",
      "\n",
      "    accuracy                         0.7050      2000\n",
      "   macro avg     0.7780    0.7024    0.7038      2000\n",
      "weighted avg     0.7777    0.7050    0.7056      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 70.50%\n",
      "Test F1 Score: 0.7038\n",
      "\n",
      "✓ Completed training configuration: mixed_augmented\n",
      "\n",
      "\n",
      "************************************************************\n",
      "Training configuration: combined_augmented\n",
      "************************************************************\n",
      "\n",
      "Loading: ./data/processed\\cifar10_train\\combined_augmented.pkl\n",
      "Training samples: 10000\n",
      "Image shape: (10000, 128, 128, 3)\n",
      "Label distribution: [1005  974 1032 1016  999  937 1030 1001 1025  981]\n",
      "Train batches: 141, Val batches: 16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 141/141 [00:04<00:00, 31.85it/s, loss=1.2198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 1.2748, Train Acc: 54.68%, Val Acc: 66.70%, Val F1: 0.6619\n",
      "  ✓ New best validation F1: 0.6619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 141/141 [00:04<00:00, 31.01it/s, loss=0.5501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Loss: 0.5467, Train Acc: 81.61%, Val Acc: 73.10%, Val F1: 0.7273\n",
      "  ✓ New best validation F1: 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 141/141 [00:05<00:00, 26.83it/s, loss=0.1900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Loss: 0.1899, Train Acc: 95.13%, Val Acc: 74.00%, Val F1: 0.7401\n",
      "  ✓ New best validation F1: 0.7401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 141/141 [00:06<00:00, 21.32it/s, loss=0.1067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Loss: 0.0523, Train Acc: 99.30%, Val Acc: 75.90%, Val F1: 0.7535\n",
      "  ✓ New best validation F1: 0.7535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 141/141 [00:09<00:00, 14.28it/s, loss=0.0210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Loss: 0.0169, Train Acc: 99.92%, Val Acc: 76.70%, Val F1: 0.7624\n",
      "  ✓ New best validation F1: 0.7624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 141/141 [00:09<00:00, 15.06it/s, loss=0.0047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Loss: 0.0082, Train Acc: 100.00%, Val Acc: 77.50%, Val F1: 0.7709\n",
      "  ✓ New best validation F1: 0.7709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 141/141 [00:10<00:00, 13.58it/s, loss=0.0113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Loss: 0.0045, Train Acc: 100.00%, Val Acc: 77.40%, Val F1: 0.7699\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 141/141 [00:09<00:00, 14.73it/s, loss=0.0062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Loss: 0.0036, Train Acc: 99.98%, Val Acc: 76.90%, Val F1: 0.7646\n",
      "  No improvement (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 141/141 [00:09<00:00, 14.18it/s, loss=0.0047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Loss: 0.0024, Train Acc: 100.00%, Val Acc: 77.80%, Val F1: 0.7751\n",
      "  ✓ New best validation F1: 0.7751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 141/141 [00:09<00:00, 14.14it/s, loss=0.0025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Loss: 0.0020, Train Acc: 100.00%, Val Acc: 77.20%, Val F1: 0.7694\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 141/141 [00:09<00:00, 15.49it/s, loss=0.0011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Loss: 0.0016, Train Acc: 100.00%, Val Acc: 76.90%, Val F1: 0.7645\n",
      "  No improvement (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 141/141 [00:04<00:00, 28.73it/s, loss=0.0009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Loss: 0.0013, Train Acc: 100.00%, Val Acc: 77.20%, Val F1: 0.7669\n",
      "  No improvement (3/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 141/141 [00:07<00:00, 18.60it/s, loss=0.0050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Loss: 0.0011, Train Acc: 100.00%, Val Acc: 77.80%, Val F1: 0.7754\n",
      "  ✓ New best validation F1: 0.7754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 141/141 [00:09<00:00, 15.65it/s, loss=0.0517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Loss: 0.0110, Train Acc: 99.72%, Val Acc: 69.20%, Val F1: 0.6924\n",
      "  No improvement (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 141/141 [00:10<00:00, 13.20it/s, loss=0.3770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Loss: 0.4109, Train Acc: 86.22%, Val Acc: 69.70%, Val F1: 0.6921\n",
      "  No improvement (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 141/141 [00:10<00:00, 13.64it/s, loss=0.0450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Loss: 0.1141, Train Acc: 96.29%, Val Acc: 75.30%, Val F1: 0.7436\n",
      "  No improvement (3/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 141/141 [00:09<00:00, 15.51it/s, loss=0.0057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Loss: 0.0225, Train Acc: 99.46%, Val Acc: 75.20%, Val F1: 0.7509\n",
      "  No improvement (4/4)\n",
      "Early stopping triggered at epoch 17\n",
      "\n",
      "Loaded best model with Val F1: 0.7754\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: original\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\original.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4272    0.8980    0.5789       196\n",
      "           1     0.6915    0.9848    0.8125       198\n",
      "           2     0.7710    0.5179    0.6196       195\n",
      "           3     0.6000    0.5729    0.5861       199\n",
      "           4     0.7917    0.5758    0.6667       198\n",
      "           5     0.5703    0.7676    0.6544       185\n",
      "           6     0.8168    0.7639    0.7895       216\n",
      "           7     0.8862    0.5648    0.6899       193\n",
      "           8     0.9000    0.4562    0.6055       217\n",
      "           9     0.8726    0.6749    0.7611       203\n",
      "\n",
      "    accuracy                         0.6760      2000\n",
      "   macro avg     0.7327    0.6777    0.6764      2000\n",
      "weighted avg     0.7363    0.6760    0.6772      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 67.60%\n",
      "Test F1 Score: 0.6764\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: all_combined\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\all_combined.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7103    0.7755    0.7415       196\n",
      "           1     0.8585    0.8889    0.8734       198\n",
      "           2     0.6731    0.7179    0.6948       195\n",
      "           3     0.6218    0.6030    0.6122       199\n",
      "           4     0.7430    0.6717    0.7056       198\n",
      "           5     0.6418    0.6973    0.6684       185\n",
      "           6     0.8108    0.8333    0.8219       216\n",
      "           7     0.8353    0.7358    0.7824       193\n",
      "           8     0.8150    0.8525    0.8333       217\n",
      "           9     0.9171    0.8177    0.8646       203\n",
      "\n",
      "    accuracy                         0.7615      2000\n",
      "   macro avg     0.7627    0.7594    0.7598      2000\n",
      "weighted avg     0.7647    0.7615    0.7619      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 76.15%\n",
      "Test F1 Score: 0.7598\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: noise\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\noise.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4816    0.7347    0.5818       196\n",
      "           1     0.6000    0.9242    0.7276       198\n",
      "           2     0.4509    0.7538    0.5643       195\n",
      "           3     0.3398    0.7889    0.4750       199\n",
      "           4     0.7043    0.4091    0.5176       198\n",
      "           5     0.7333    0.4757    0.5770       185\n",
      "           6     0.8829    0.4537    0.5994       216\n",
      "           7     0.9571    0.3472    0.5095       193\n",
      "           8     0.9710    0.3088    0.4685       217\n",
      "           9     0.8537    0.5172    0.6442       203\n",
      "\n",
      "    accuracy                         0.5685      2000\n",
      "   macro avg     0.6975    0.5713    0.5665      2000\n",
      "weighted avg     0.7017    0.5685    0.5661      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 56.85%\n",
      "Test F1 Score: 0.5665\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: occlusion_25\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\occlusion_25.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4051    0.8929    0.5573       196\n",
      "           1     0.7302    0.9293    0.8178       198\n",
      "           2     0.7073    0.4462    0.5472       195\n",
      "           3     0.5460    0.4472    0.4917       199\n",
      "           4     0.7559    0.4848    0.5908       198\n",
      "           5     0.4601    0.7784    0.5783       185\n",
      "           6     0.8208    0.6574    0.7301       216\n",
      "           7     0.8390    0.5130    0.6367       193\n",
      "           8     0.8598    0.4240    0.5679       217\n",
      "           9     0.7760    0.7340    0.7544       203\n",
      "\n",
      "    accuracy                         0.6285      2000\n",
      "   macro avg     0.6900    0.6307    0.6272      2000\n",
      "weighted avg     0.6943    0.6285    0.6283      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 62.85%\n",
      "Test F1 Score: 0.6272\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: rotation_15\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\rotation_15.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6117    0.8520    0.7122       196\n",
      "           1     0.8000    0.9091    0.8511       198\n",
      "           2     0.7062    0.6410    0.6720       195\n",
      "           3     0.5571    0.6131    0.5837       199\n",
      "           4     0.8425    0.6212    0.7151       198\n",
      "           5     0.5885    0.7730    0.6682       185\n",
      "           6     0.9162    0.7593    0.8304       216\n",
      "           7     0.8636    0.6891    0.7666       193\n",
      "           8     0.8641    0.7327    0.7930       217\n",
      "           9     0.8600    0.8473    0.8536       203\n",
      "\n",
      "    accuracy                         0.7440      2000\n",
      "   macro avg     0.7610    0.7438    0.7446      2000\n",
      "weighted avg     0.7646    0.7440    0.7466      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 74.40%\n",
      "Test F1 Score: 0.7446\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Evaluating on test set: scaling_0.8\n",
      "────────────────────────────────────────────────────────────\n",
      "Loading: ./data/processed\\cifar10_test\\scaling_0.8.pkl\n",
      "Test samples: 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5116    0.9031    0.6531       196\n",
      "           1     0.7885    0.9040    0.8424       198\n",
      "           2     0.8227    0.5949    0.6905       195\n",
      "           3     0.6941    0.5930    0.6396       199\n",
      "           4     0.8171    0.6768    0.7403       198\n",
      "           5     0.6217    0.7730    0.6892       185\n",
      "           6     0.8000    0.8704    0.8337       216\n",
      "           7     0.8980    0.6839    0.7765       193\n",
      "           8     0.8710    0.7465    0.8040       217\n",
      "           9     0.9351    0.7094    0.8067       203\n",
      "\n",
      "    accuracy                         0.7465      2000\n",
      "   macro avg     0.7760    0.7455    0.7476      2000\n",
      "weighted avg     0.7783    0.7465    0.7495      2000\n",
      "\n",
      "\n",
      "Test Accuracy: 74.65%\n",
      "Test F1 Score: 0.7476\n",
      "\n",
      "✓ Completed training configuration: combined_augmented\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import models\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# =====================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================\n",
    "DATA_DIR = \"./data/processed\"\n",
    "SAVE_DIR = \"./resnet-18\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "EPOCHS = 20\n",
    "PATIENCE = 4\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "TRAIN_LIMIT = 10000\n",
    "TEST_LIMIT = 2000\n",
    "VAL_SPLIT = 0.1  # 10% for validation\n",
    "\n",
    "# =====================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =====================================================\n",
    "\n",
    "def load_dataset(dataset_name, split_type, aug_type):\n",
    "    \"\"\"Load dataset from pickle file.\"\"\"\n",
    "    path = os.path.join(DATA_DIR, f\"{dataset_name}_{split_type}\", f\"{aug_type}.pkl\")\n",
    "    print(f\"Loading: {path}\")\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data[\"images\"], data[\"labels\"]\n",
    "\n",
    "def preprocess_images(images, dataset_type):\n",
    "    \"\"\"Convert images to tensor format and normalize.\"\"\"\n",
    "    # Ensure 4D: (N, H, W, C)\n",
    "    if images.ndim == 3:\n",
    "        images = np.expand_dims(images, axis=-1)\n",
    "    \n",
    "    # Transpose to PyTorch format: (N, C, H, W)\n",
    "    images = images.transpose(0, 3, 1, 2)\n",
    "    \n",
    "    # Convert to tensor and normalize to [0, 1]\n",
    "    tensor = torch.tensor(images, dtype=torch.float32)\n",
    "    if tensor.max() > 1.0:\n",
    "        tensor = tensor / 255.0\n",
    "    \n",
    "    # Convert grayscale to RGB by repeating channels\n",
    "    if dataset_type == \"grayscale\" and tensor.shape[1] == 1:\n",
    "        tensor = tensor.repeat(1, 3, 1, 1)\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "def get_model(num_classes, pretrained=True):\n",
    "    \"\"\"Initialize ResNet-18 model.\"\"\"\n",
    "    if pretrained:\n",
    "        model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "    else:\n",
    "        model = models.resnet18(weights=None)\n",
    "    \n",
    "    # Replace final layer for our number of classes\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=EPOCHS, patience=PATIENCE):\n",
    "    \"\"\"Train model with early stopping.\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    best_val_f1 = 0\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for X, y in pbar:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += y.size(0)\n",
    "            train_correct += (predicted == y).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        val_f1, val_acc = evaluate_model(model, val_loader, return_accuracy=True)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "              f\"Loss: {avg_loss:.4f}, \"\n",
    "              f\"Train Acc: {train_acc:.2f}%, \"\n",
    "              f\"Val Acc: {val_acc:.2f}%, \"\n",
    "              f\"Val F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            patience_counter = 0\n",
    "            best_state = model.state_dict().copy()\n",
    "            print(f\"  ✓ New best validation F1: {best_val_f1:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  No improvement ({patience_counter}/{patience})\")\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(f\"\\nLoaded best model with Val F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "    return model, best_val_f1\n",
    "\n",
    "def evaluate_model(model, data_loader, return_accuracy=False, silent=False):\n",
    "    \"\"\"Evaluate model on given data loader.\"\"\"\n",
    "    model.eval()\n",
    "    preds, true = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            preds.extend(predicted.cpu().numpy())\n",
    "            true.extend(y.cpu().numpy())\n",
    "    \n",
    "    f1 = f1_score(true, preds, average=\"macro\")\n",
    "    \n",
    "    if return_accuracy:\n",
    "        acc = 100 * np.mean(np.array(true) == np.array(preds))\n",
    "        return f1, acc\n",
    "    \n",
    "    if not silent:\n",
    "        report = classification_report(true, preds, digits=4)\n",
    "        print(report)\n",
    "        return f1, true, preds\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU and CPU memory.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# =====================================================\n",
    "# MAIN EXECUTION\n",
    "# =====================================================\n",
    "\n",
    "datasets = {\n",
    "    \"mnist\": {\"classes\": 10, \"type\": \"grayscale\"},\n",
    "    \"cifar10\": {\"classes\": 10, \"type\": \"color\"}\n",
    "}\n",
    "\n",
    "train_types = [\"original\", \"mixed_augmented\", \"combined_augmented\"]\n",
    "test_types = [\"original\", \"all_combined\", \"noise\", \"occlusion_25\", \"rotation_15\", \"scaling_0.8\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "for dataset_name, info in datasets.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PROCESSING DATASET: {dataset_name.upper()}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for train_aug in train_types:\n",
    "        print(f\"\\n{'*'*60}\")\n",
    "        print(f\"Training configuration: {train_aug}\")\n",
    "        print(f\"{'*'*60}\\n\")\n",
    "        \n",
    "        # Load training data ONCE\n",
    "        train_images, train_labels = load_dataset(dataset_name, \"train\", train_aug)\n",
    "        train_images = train_images[:TRAIN_LIMIT]\n",
    "        train_labels = train_labels[:TRAIN_LIMIT]\n",
    "        \n",
    "        print(f\"Training samples: {len(train_images)}\")\n",
    "        print(f\"Image shape: {train_images.shape}\")\n",
    "        print(f\"Label distribution: {np.bincount(train_labels)}\")\n",
    "        \n",
    "        # Preprocess training data\n",
    "        X_train = preprocess_images(train_images, info[\"type\"])\n",
    "        y_train = torch.tensor(train_labels, dtype=torch.long)\n",
    "        \n",
    "        # Create train/val split\n",
    "        full_dataset = TensorDataset(X_train, y_train)\n",
    "        train_size = int((1 - VAL_SPLIT) * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        \n",
    "        # Use fixed seed for reproducibility\n",
    "        torch.manual_seed(42)\n",
    "        train_subset, val_subset = torch.utils.data.random_split(\n",
    "            full_dataset, [train_size, val_size]\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_subset, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_subset, \n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=0,\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "        \n",
    "        print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\\n\")\n",
    "        \n",
    "        # Train model ONCE per training configuration\n",
    "        model = get_model(info[\"classes\"])\n",
    "        model, best_val_f1 = train_model(model, train_loader, val_loader)\n",
    "        \n",
    "        # Evaluate on all test sets\n",
    "        for test_aug in test_types:\n",
    "            print(f\"\\n{'─'*60}\")\n",
    "            print(f\"Evaluating on test set: {test_aug}\")\n",
    "            print(f\"{'─'*60}\")\n",
    "            \n",
    "            # Load test data\n",
    "            test_images, test_labels = load_dataset(dataset_name, \"test\", test_aug)\n",
    "            test_images = test_images[:TEST_LIMIT]\n",
    "            test_labels = test_labels[:TEST_LIMIT]\n",
    "            \n",
    "            print(f\"Test samples: {len(test_images)}\")\n",
    "            \n",
    "            # Preprocess test data\n",
    "            X_test = preprocess_images(test_images, info[\"type\"])\n",
    "            y_test = torch.tensor(test_labels, dtype=torch.long)\n",
    "            \n",
    "            test_loader = DataLoader(\n",
    "                TensorDataset(X_test, y_test), \n",
    "                batch_size=BATCH_SIZE,\n",
    "                num_workers=0,\n",
    "                pin_memory=True if torch.cuda.is_available() else False\n",
    "            )\n",
    "            \n",
    "            # Evaluate\n",
    "            test_f1, y_true, y_pred = evaluate_model(model, test_loader)\n",
    "            test_acc = 100 * np.mean(np.array(y_true) == np.array(y_pred))\n",
    "            \n",
    "            print(f\"\\nTest Accuracy: {test_acc:.2f}%\")\n",
    "            print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "            \n",
    "            # Save detailed report\n",
    "            report = classification_report(y_true, y_pred, digits=4)\n",
    "            report_path = os.path.join(\n",
    "                SAVE_DIR, \n",
    "                f\"{dataset_name}_train-{train_aug}_test-{test_aug}.txt\"\n",
    "            )\n",
    "            with open(report_path, \"w\") as f:\n",
    "                f.write(f\"Dataset: {dataset_name}\\n\")\n",
    "                f.write(f\"Training Type: {train_aug}\\n\")\n",
    "                f.write(f\"Test Type: {test_aug}\\n\")\n",
    "                f.write(f\"{'='*60}\\n\\n\")\n",
    "                f.write(report)\n",
    "                f.write(f\"\\n{'='*60}\\n\")\n",
    "                f.write(f\"Best Validation F1: {best_val_f1:.4f}\\n\")\n",
    "                f.write(f\"Test F1: {test_f1:.4f}\\n\")\n",
    "                f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                \"dataset\": dataset_name,\n",
    "                \"train_type\": train_aug,\n",
    "                \"test_type\": test_aug,\n",
    "                \"best_val_f1\": best_val_f1,\n",
    "                \"test_f1\": test_f1,\n",
    "                \"test_accuracy\": test_acc\n",
    "            })\n",
    "            \n",
    "            # Clean up test data\n",
    "            del X_test, y_test, test_loader, test_images, test_labels\n",
    "            clear_memory()\n",
    "        \n",
    "        # Clean up model and training data after all test evaluations\n",
    "        del model, X_train, y_train, train_loader, val_loader, train_images, train_labels\n",
    "        del train_subset, val_subset, full_dataset\n",
    "        clear_memory()\n",
    "        \n",
    "        print(f\"\\n✓ Completed training configuration: {train_aug}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e312c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXPERIMENT SUMMARY\n",
      "================================================================================\n",
      "\n",
      "dataset         train_type    test_type  best_val_f1  test_f1  test_accuracy\n",
      "  mnist           original     original     0.991041 0.989169          98.95\n",
      "  mnist           original all_combined     0.991041 0.367146          40.15\n",
      "  mnist           original        noise     0.991041 0.091232          16.55\n",
      "  mnist           original occlusion_25     0.991041 0.922393          92.35\n",
      "  mnist           original  rotation_15     0.991041 0.975389          97.55\n",
      "  mnist           original  scaling_0.8     0.991041 0.983435          98.35\n",
      "  mnist    mixed_augmented     original     0.990962 0.985232          98.50\n",
      "  mnist    mixed_augmented all_combined     0.990962 0.354786          39.85\n",
      "  mnist    mixed_augmented        noise     0.990962 0.138574          26.45\n",
      "  mnist    mixed_augmented occlusion_25     0.990962 0.891756          89.10\n",
      "  mnist    mixed_augmented  rotation_15     0.990962 0.946534          94.60\n",
      "  mnist    mixed_augmented  scaling_0.8     0.990962 0.978757          97.90\n",
      "  mnist combined_augmented     original     0.975020 0.916771          91.60\n",
      "  mnist combined_augmented all_combined     0.975020 0.964439          96.45\n",
      "  mnist combined_augmented        noise     0.975020 0.882641          87.85\n",
      "  mnist combined_augmented occlusion_25     0.975020 0.879423          87.75\n",
      "  mnist combined_augmented  rotation_15     0.975020 0.956199          95.60\n",
      "  mnist combined_augmented  scaling_0.8     0.975020 0.912233          90.80\n",
      "cifar10           original     original     0.924822 0.856681          85.80\n",
      "cifar10           original all_combined     0.924822 0.076855          13.55\n",
      "cifar10           original        noise     0.924822 0.084790          15.25\n",
      "cifar10           original occlusion_25     0.924822 0.742187          74.05\n",
      "cifar10           original  rotation_15     0.924822 0.530292          53.15\n",
      "cifar10           original  scaling_0.8     0.924822 0.625646          63.20\n",
      "cifar10    mixed_augmented     original     0.903410 0.866245          86.60\n",
      "cifar10    mixed_augmented all_combined     0.903410 0.190940          23.10\n",
      "cifar10    mixed_augmented        noise     0.903410 0.312845          33.50\n",
      "cifar10    mixed_augmented occlusion_25     0.903410 0.712700          70.00\n",
      "cifar10    mixed_augmented  rotation_15     0.903410 0.504383          53.40\n",
      "cifar10    mixed_augmented  scaling_0.8     0.903410 0.703799          70.50\n",
      "cifar10 combined_augmented     original     0.775375 0.676420          67.60\n",
      "cifar10 combined_augmented all_combined     0.775375 0.759811          76.15\n",
      "cifar10 combined_augmented        noise     0.775375 0.566501          56.85\n",
      "cifar10 combined_augmented occlusion_25     0.775375 0.627213          62.85\n",
      "cifar10 combined_augmented  rotation_15     0.775375 0.744590          74.40\n",
      "cifar10 combined_augmented  scaling_0.8     0.775375 0.747589          74.65\n",
      "\n",
      "✓ All experiments complete!\n",
      "✓ Summary saved to: ./resnet-18\\resnet18_results.csv\n",
      "✓ Individual reports saved to: ./resnet-18/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================================\n",
    "# SAVE SUMMARY\n",
    "# =====================================================\n",
    "df = pd.DataFrame(results)\n",
    "csv_path = os.path.join(SAVE_DIR, \"resnet18_results.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\n✓ All experiments complete!\")\n",
    "print(f\"✓ Summary saved to: {csv_path}\")\n",
    "print(f\"✓ Individual reports saved to: {SAVE_DIR}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87f089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
