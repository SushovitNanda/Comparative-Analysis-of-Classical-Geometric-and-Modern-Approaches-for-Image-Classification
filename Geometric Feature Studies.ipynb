{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8849a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "GEOMETRY-BASED CLASSIFICATION PIPELINE FOR MNIST\n",
      "3 Training Sets x 6 Test Sets = 18 Classifications per Model\n",
      "====================================================================================================\n",
      "\n",
      "Step 1: Loading all MNIST datasets...\n",
      "✓ Loaded original: 10000 samples\n",
      "✓ Loaded mixed_augmented: 10000 samples\n",
      "✓ Loaded combined_augmented: 10000 samples\n",
      "✓ Loaded original: 2000 samples\n",
      "✓ Loaded rotation_15: 2000 samples\n",
      "✓ Loaded noise: 2000 samples\n",
      "✓ Loaded scaling_0.8: 2000 samples\n",
      "✓ Loaded occlusion_25: 2000 samples\n",
      "✓ Loaded all_combined: 2000 samples\n",
      "\n",
      "Step 2: Saving visualization samples...\n",
      "\n",
      "Saving 5 visualization samples...\n",
      "✓ Saved visualizations to ./geometric_results\\visualizations\n",
      "\n",
      "Step 3: Extracting geometry features for all datasets...\n",
      "\n",
      "  Processing training set: original\n",
      "Extracting geometry features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 10000/10000 [16:06<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing training set: mixed_augmented\n",
      "Extracting geometry features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 10000/10000 [11:44<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing training set: combined_augmented\n",
      "Extracting geometry features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 10000/10000 [16:29<00:00, 10.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing test set: original\n",
      "Extracting geometry features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 2000/2000 [02:37<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing test set: rotation_15\n",
      "Extracting geometry features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 2000/2000 [03:24<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing test set: noise\n",
      "Extracting geometry features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 2000/2000 [02:10<00:00, 15.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing test set: scaling_0.8\n",
      "Extracting geometry features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 2000/2000 [01:42<00:00, 19.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing test set: occlusion_25\n",
      "Extracting geometry features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 2000/2000 [02:07<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing test set: all_combined\n",
      "Extracting geometry features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 2000/2000 [01:57<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Feature extraction completed for all datasets\n",
      "\n",
      "Step 4: Training and evaluating models...\n",
      "Total combinations: 3 train x 6 test = 18\n",
      "\n",
      "####################################################################################################\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "####################################################################################################\n",
      "\n",
      "[Combination 1/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: ORIGINAL\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.4540\n",
      "  F1-Macro: 0.4212\n",
      "  F1-Weighted: 0.4318\n",
      "  Training Time: 2.09s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.4080\n",
      "  F1-Macro: 0.3776\n",
      "  F1-Weighted: 0.3887\n",
      "  Training Time: 0.09s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.4360\n",
      "  F1-Macro: 0.4085\n",
      "  F1-Weighted: 0.4197\n",
      "  Training Time: 24.12s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.3970\n",
      "  F1-Macro: 0.3779\n",
      "  F1-Weighted: 0.3891\n",
      "  Training Time: 0.50s\n",
      "\n",
      "[Combination 2/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: ROTATION_15\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1150\n",
      "  F1-Macro: 0.0531\n",
      "  F1-Weighted: 0.0514\n",
      "  Training Time: 7.42s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1385\n",
      "  F1-Macro: 0.0640\n",
      "  F1-Weighted: 0.0601\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1015\n",
      "  F1-Macro: 0.0463\n",
      "  F1-Weighted: 0.0447\n",
      "  Training Time: 41.88s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1255\n",
      "  F1-Macro: 0.0854\n",
      "  F1-Weighted: 0.0809\n",
      "  Training Time: 0.21s\n",
      "\n",
      "[Combination 3/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: NOISE\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1080\n",
      "  F1-Macro: 0.0195\n",
      "  F1-Weighted: 0.0211\n",
      "  Training Time: 2.33s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.0965\n",
      "  F1-Macro: 0.0176\n",
      "  F1-Weighted: 0.0170\n",
      "  Training Time: 0.06s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1080\n",
      "  F1-Macro: 0.0195\n",
      "  F1-Weighted: 0.0211\n",
      "  Training Time: 40.53s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1220\n",
      "  F1-Macro: 0.0708\n",
      "  F1-Weighted: 0.0694\n",
      "  Training Time: 0.25s\n",
      "\n",
      "[Combination 4/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: SCALING_0.8\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2610\n",
      "  F1-Macro: 0.2066\n",
      "  F1-Weighted: 0.2132\n",
      "  Training Time: 5.77s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2385\n",
      "  F1-Macro: 0.1805\n",
      "  F1-Weighted: 0.1882\n",
      "  Training Time: 0.28s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2615\n",
      "  F1-Macro: 0.2041\n",
      "  F1-Weighted: 0.2113\n",
      "  Training Time: 29.46s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2705\n",
      "  F1-Macro: 0.2211\n",
      "  F1-Weighted: 0.2284\n",
      "  Training Time: 0.19s\n",
      "\n",
      "[Combination 5/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: OCCLUSION_25\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.4025\n",
      "  F1-Macro: 0.3659\n",
      "  F1-Weighted: 0.3870\n",
      "  Training Time: 2.31s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.3810\n",
      "  F1-Macro: 0.3423\n",
      "  F1-Weighted: 0.3632\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.3960\n",
      "  F1-Macro: 0.3627\n",
      "  F1-Weighted: 0.3832\n",
      "  Training Time: 27.47s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.3490\n",
      "  F1-Macro: 0.3201\n",
      "  F1-Weighted: 0.3415\n",
      "  Training Time: 0.21s\n",
      "\n",
      "[Combination 6/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: ALL_COMBINED\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1060\n",
      "  F1-Macro: 0.0200\n",
      "  F1-Weighted: 0.0211\n",
      "  Training Time: 2.48s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1120\n",
      "  F1-Macro: 0.0323\n",
      "  F1-Weighted: 0.0329\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1065\n",
      "  F1-Macro: 0.0346\n",
      "  F1-Weighted: 0.0363\n",
      "  Training Time: 22.73s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1310\n",
      "  F1-Macro: 0.0791\n",
      "  F1-Weighted: 0.0803\n",
      "  Training Time: 0.20s\n",
      "\n",
      "[Combination 7/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: ORIGINAL\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.3155\n",
      "  F1-Macro: 0.2538\n",
      "  F1-Weighted: 0.2596\n",
      "  Training Time: 3.04s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2655\n",
      "  F1-Macro: 0.2001\n",
      "  F1-Weighted: 0.2046\n",
      "  Training Time: 0.06s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.3745\n",
      "  F1-Macro: 0.3308\n",
      "  F1-Weighted: 0.3409\n",
      "  Training Time: 22.79s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.3345\n",
      "  F1-Macro: 0.3134\n",
      "  F1-Weighted: 0.3231\n",
      "  Training Time: 0.18s\n",
      "\n",
      "[Combination 8/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: ROTATION_15\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.3285\n",
      "  F1-Macro: 0.2714\n",
      "  F1-Weighted: 0.2830\n",
      "  Training Time: 3.05s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2385\n",
      "  F1-Macro: 0.1577\n",
      "  F1-Weighted: 0.1597\n",
      "  Training Time: 0.06s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2800\n",
      "  F1-Macro: 0.2392\n",
      "  F1-Weighted: 0.2423\n",
      "  Training Time: 33.58s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2195\n",
      "  F1-Macro: 0.2231\n",
      "  F1-Weighted: 0.2281\n",
      "  Training Time: 0.19s\n",
      "\n",
      "[Combination 9/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: NOISE\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2520\n",
      "  F1-Macro: 0.1713\n",
      "  F1-Weighted: 0.1764\n",
      "  Training Time: 3.05s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2245\n",
      "  F1-Macro: 0.1417\n",
      "  F1-Weighted: 0.1446\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2500\n",
      "  F1-Macro: 0.1966\n",
      "  F1-Weighted: 0.2024\n",
      "  Training Time: 34.00s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1740\n",
      "  F1-Macro: 0.1688\n",
      "  F1-Weighted: 0.1697\n",
      "  Training Time: 0.21s\n",
      "\n",
      "[Combination 10/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: SCALING_0.8\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2965\n",
      "  F1-Macro: 0.2453\n",
      "  F1-Weighted: 0.2482\n",
      "  Training Time: 3.07s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2670\n",
      "  F1-Macro: 0.2028\n",
      "  F1-Weighted: 0.2065\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.3175\n",
      "  F1-Macro: 0.2716\n",
      "  F1-Weighted: 0.2766\n",
      "  Training Time: 33.99s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.3320\n",
      "  F1-Macro: 0.3019\n",
      "  F1-Weighted: 0.3114\n",
      "  Training Time: 0.18s\n",
      "\n",
      "[Combination 11/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: OCCLUSION_25\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.3045\n",
      "  F1-Macro: 0.2370\n",
      "  F1-Weighted: 0.2488\n",
      "  Training Time: 3.06s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2780\n",
      "  F1-Macro: 0.2007\n",
      "  F1-Weighted: 0.2124\n",
      "  Training Time: 0.06s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.3625\n",
      "  F1-Macro: 0.3138\n",
      "  F1-Weighted: 0.3312\n",
      "  Training Time: 34.68s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.3495\n",
      "  F1-Macro: 0.3213\n",
      "  F1-Weighted: 0.3398\n",
      "  Training Time: 0.20s\n",
      "\n",
      "[Combination 12/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: ALL_COMBINED\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1895\n",
      "  F1-Macro: 0.1408\n",
      "  F1-Weighted: 0.1380\n",
      "  Training Time: 3.02s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2140\n",
      "  F1-Macro: 0.1418\n",
      "  F1-Weighted: 0.1465\n",
      "  Training Time: 0.06s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1530\n",
      "  F1-Macro: 0.1052\n",
      "  F1-Weighted: 0.1043\n",
      "  Training Time: 33.29s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1295\n",
      "  F1-Macro: 0.1052\n",
      "  F1-Weighted: 0.1048\n",
      "  Training Time: 0.19s\n",
      "\n",
      "[Combination 13/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: ORIGINAL\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.0915\n",
      "  F1-Macro: 0.0523\n",
      "  F1-Weighted: 0.0509\n",
      "  Training Time: 3.55s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2115\n",
      "  F1-Macro: 0.1184\n",
      "  F1-Weighted: 0.1223\n",
      "  Training Time: 0.08s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2065\n",
      "  F1-Macro: 0.1096\n",
      "  F1-Weighted: 0.1160\n",
      "  Training Time: 59.73s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2460\n",
      "  F1-Macro: 0.1994\n",
      "  F1-Weighted: 0.2048\n",
      "  Training Time: 0.17s\n",
      "\n",
      "[Combination 14/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: ROTATION_15\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2105\n",
      "  F1-Macro: 0.1518\n",
      "  F1-Weighted: 0.1509\n",
      "  Training Time: 3.43s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2295\n",
      "  F1-Macro: 0.1335\n",
      "  F1-Weighted: 0.1370\n",
      "  Training Time: 0.10s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1955\n",
      "  F1-Macro: 0.1030\n",
      "  F1-Weighted: 0.1059\n",
      "  Training Time: 31.92s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2195\n",
      "  F1-Macro: 0.1618\n",
      "  F1-Weighted: 0.1638\n",
      "  Training Time: 0.17s\n",
      "\n",
      "[Combination 15/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: NOISE\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.0875\n",
      "  F1-Macro: 0.0161\n",
      "  F1-Weighted: 0.0141\n",
      "  Training Time: 3.43s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1290\n",
      "  F1-Macro: 0.0438\n",
      "  F1-Weighted: 0.0445\n",
      "  Training Time: 0.08s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.0965\n",
      "  F1-Macro: 0.0176\n",
      "  F1-Weighted: 0.0170\n",
      "  Training Time: 43.40s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1220\n",
      "  F1-Macro: 0.1050\n",
      "  F1-Weighted: 0.1046\n",
      "  Training Time: 0.18s\n",
      "\n",
      "[Combination 16/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: SCALING_0.8\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.0900\n",
      "  F1-Macro: 0.0327\n",
      "  F1-Weighted: 0.0305\n",
      "  Training Time: 3.44s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1685\n",
      "  F1-Macro: 0.0628\n",
      "  F1-Weighted: 0.0677\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2030\n",
      "  F1-Macro: 0.0993\n",
      "  F1-Weighted: 0.1059\n",
      "  Training Time: 38.59s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2410\n",
      "  F1-Macro: 0.2020\n",
      "  F1-Weighted: 0.2067\n",
      "  Training Time: 0.19s\n",
      "\n",
      "[Combination 17/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: OCCLUSION_25\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.0830\n",
      "  F1-Macro: 0.0493\n",
      "  F1-Weighted: 0.0502\n",
      "  Training Time: 3.45s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2140\n",
      "  F1-Macro: 0.1103\n",
      "  F1-Weighted: 0.1223\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2075\n",
      "  F1-Macro: 0.1004\n",
      "  F1-Weighted: 0.1127\n",
      "  Training Time: 35.23s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2395\n",
      "  F1-Macro: 0.1771\n",
      "  F1-Weighted: 0.1880\n",
      "  Training Time: 0.19s\n",
      "\n",
      "[Combination 18/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: ALL_COMBINED\n",
      "FEATURE TYPE: HOUGH_TRANSFORM\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 6\n",
      "Test samples: 2000, Features: 6\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2505\n",
      "  F1-Macro: 0.2062\n",
      "  F1-Weighted: 0.2063\n",
      "  Training Time: 3.55s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2460\n",
      "  F1-Macro: 0.1901\n",
      "  F1-Weighted: 0.1932\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2455\n",
      "  F1-Macro: 0.2119\n",
      "  F1-Weighted: 0.2132\n",
      "  Training Time: 36.14s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2035\n",
      "  F1-Macro: 0.1958\n",
      "  F1-Weighted: 0.1986\n",
      "  Training Time: 0.19s\n",
      "\n",
      "####################################################################################################\n",
      "FEATURE TYPE: RANSAC\n",
      "####################################################################################################\n",
      "\n",
      "[Combination 19/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: ORIGINAL\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2545\n",
      "  F1-Macro: 0.2208\n",
      "  F1-Weighted: 0.2241\n",
      "  Training Time: 2.98s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2450\n",
      "  F1-Macro: 0.2018\n",
      "  F1-Weighted: 0.2067\n",
      "  Training Time: 0.02s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2620\n",
      "  F1-Macro: 0.2302\n",
      "  F1-Weighted: 0.2337\n",
      "  Training Time: 18.11s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2055\n",
      "  F1-Macro: 0.2026\n",
      "  F1-Weighted: 0.2063\n",
      "  Training Time: 0.20s\n",
      "\n",
      "[Combination 20/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: ROTATION_15\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1630\n",
      "  F1-Macro: 0.1147\n",
      "  F1-Weighted: 0.1118\n",
      "  Training Time: 3.00s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1560\n",
      "  F1-Macro: 0.1049\n",
      "  F1-Weighted: 0.1031\n",
      "  Training Time: 0.02s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1955\n",
      "  F1-Macro: 0.1430\n",
      "  F1-Weighted: 0.1395\n",
      "  Training Time: 15.78s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1600\n",
      "  F1-Macro: 0.1491\n",
      "  F1-Weighted: 0.1471\n",
      "  Training Time: 0.22s\n",
      "\n",
      "[Combination 21/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: NOISE\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1145\n",
      "  F1-Macro: 0.0206\n",
      "  F1-Weighted: 0.0235\n",
      "  Training Time: 2.96s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1080\n",
      "  F1-Macro: 0.0195\n",
      "  F1-Weighted: 0.0211\n",
      "  Training Time: 0.03s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1145\n",
      "  F1-Macro: 0.0205\n",
      "  F1-Weighted: 0.0235\n",
      "  Training Time: 22.48s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1135\n",
      "  F1-Macro: 0.0374\n",
      "  F1-Weighted: 0.0416\n",
      "  Training Time: 0.23s\n",
      "\n",
      "[Combination 22/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: SCALING_0.8\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2355\n",
      "  F1-Macro: 0.1798\n",
      "  F1-Weighted: 0.1875\n",
      "  Training Time: 2.96s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1875\n",
      "  F1-Macro: 0.1215\n",
      "  F1-Weighted: 0.1269\n",
      "  Training Time: 0.02s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2335\n",
      "  F1-Macro: 0.1733\n",
      "  F1-Weighted: 0.1805\n",
      "  Training Time: 14.53s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2055\n",
      "  F1-Macro: 0.1710\n",
      "  F1-Weighted: 0.1758\n",
      "  Training Time: 0.27s\n",
      "\n",
      "[Combination 23/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: OCCLUSION_25\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2710\n",
      "  F1-Macro: 0.2312\n",
      "  F1-Weighted: 0.2455\n",
      "  Training Time: 3.09s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2480\n",
      "  F1-Macro: 0.2007\n",
      "  F1-Weighted: 0.2149\n",
      "  Training Time: 0.02s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2665\n",
      "  F1-Macro: 0.2295\n",
      "  F1-Weighted: 0.2408\n",
      "  Training Time: 10.69s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2165\n",
      "  F1-Macro: 0.2089\n",
      "  F1-Weighted: 0.2184\n",
      "  Training Time: 0.24s\n",
      "\n",
      "[Combination 24/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: ALL_COMBINED\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1025\n",
      "  F1-Macro: 0.0222\n",
      "  F1-Weighted: 0.0227\n",
      "  Training Time: 2.92s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1045\n",
      "  F1-Macro: 0.0262\n",
      "  F1-Weighted: 0.0267\n",
      "  Training Time: 0.02s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.0930\n",
      "  F1-Macro: 0.0428\n",
      "  F1-Weighted: 0.0444\n",
      "  Training Time: 24.45s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.0955\n",
      "  F1-Macro: 0.0729\n",
      "  F1-Weighted: 0.0732\n",
      "  Training Time: 0.20s\n",
      "\n",
      "[Combination 25/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: ORIGINAL\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2550\n",
      "  F1-Macro: 0.2054\n",
      "  F1-Weighted: 0.2082\n",
      "  Training Time: 3.18s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1995\n",
      "  F1-Macro: 0.1452\n",
      "  F1-Weighted: 0.1497\n",
      "  Training Time: 0.02s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2605\n",
      "  F1-Macro: 0.2232\n",
      "  F1-Weighted: 0.2262\n",
      "  Training Time: 33.56s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2055\n",
      "  F1-Macro: 0.2011\n",
      "  F1-Weighted: 0.2044\n",
      "  Training Time: 0.21s\n",
      "\n",
      "[Combination 26/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: ROTATION_15\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1795\n",
      "  F1-Macro: 0.1356\n",
      "  F1-Weighted: 0.1316\n",
      "  Training Time: 3.28s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1840\n",
      "  F1-Macro: 0.1394\n",
      "  F1-Weighted: 0.1416\n",
      "  Training Time: 0.02s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1980\n",
      "  F1-Macro: 0.1473\n",
      "  F1-Weighted: 0.1431\n",
      "  Training Time: 20.87s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1630\n",
      "  F1-Macro: 0.1519\n",
      "  F1-Weighted: 0.1495\n",
      "  Training Time: 0.22s\n",
      "\n",
      "[Combination 27/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: NOISE\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1145\n",
      "  F1-Macro: 0.0205\n",
      "  F1-Weighted: 0.0235\n",
      "  Training Time: 3.24s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1135\n",
      "  F1-Macro: 0.0385\n",
      "  F1-Weighted: 0.0395\n",
      "  Training Time: 0.02s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.0985\n",
      "  F1-Macro: 0.0240\n",
      "  F1-Weighted: 0.0236\n",
      "  Training Time: 33.78s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1085\n",
      "  F1-Macro: 0.1080\n",
      "  F1-Weighted: 0.1088\n",
      "  Training Time: 0.22s\n",
      "\n",
      "[Combination 28/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: SCALING_0.8\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2510\n",
      "  F1-Macro: 0.1946\n",
      "  F1-Weighted: 0.2028\n",
      "  Training Time: 3.14s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1735\n",
      "  F1-Macro: 0.0905\n",
      "  F1-Weighted: 0.0948\n",
      "  Training Time: 0.02s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2570\n",
      "  F1-Macro: 0.2065\n",
      "  F1-Weighted: 0.2136\n",
      "  Training Time: 35.33s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2140\n",
      "  F1-Macro: 0.1935\n",
      "  F1-Weighted: 0.1986\n",
      "  Training Time: 0.21s\n",
      "\n",
      "[Combination 29/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: OCCLUSION_25\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2680\n",
      "  F1-Macro: 0.2128\n",
      "  F1-Weighted: 0.2277\n",
      "  Training Time: 3.22s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1940\n",
      "  F1-Macro: 0.1350\n",
      "  F1-Weighted: 0.1475\n",
      "  Training Time: 0.01s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2585\n",
      "  F1-Macro: 0.2204\n",
      "  F1-Weighted: 0.2317\n",
      "  Training Time: 34.70s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2105\n",
      "  F1-Macro: 0.2030\n",
      "  F1-Weighted: 0.2124\n",
      "  Training Time: 0.23s\n",
      "\n",
      "[Combination 30/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: ALL_COMBINED\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1040\n",
      "  F1-Macro: 0.0367\n",
      "  F1-Weighted: 0.0378\n",
      "  Training Time: 3.11s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1195\n",
      "  F1-Macro: 0.0607\n",
      "  F1-Weighted: 0.0619\n",
      "  Training Time: 0.02s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1010\n",
      "  F1-Macro: 0.0382\n",
      "  F1-Weighted: 0.0392\n",
      "  Training Time: 33.70s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.0985\n",
      "  F1-Macro: 0.0723\n",
      "  F1-Weighted: 0.0737\n",
      "  Training Time: 0.21s\n",
      "\n",
      "[Combination 31/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: ORIGINAL\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1225\n",
      "  F1-Macro: 0.0519\n",
      "  F1-Weighted: 0.0549\n",
      "  Training Time: 3.84s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1560\n",
      "  F1-Macro: 0.0606\n",
      "  F1-Weighted: 0.0642\n",
      "  Training Time: 0.01s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1225\n",
      "  F1-Macro: 0.0584\n",
      "  F1-Weighted: 0.0610\n",
      "  Training Time: 34.45s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.0950\n",
      "  F1-Macro: 0.0882\n",
      "  F1-Weighted: 0.0894\n",
      "  Training Time: 0.22s\n",
      "\n",
      "[Combination 32/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: ROTATION_15\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1275\n",
      "  F1-Macro: 0.0572\n",
      "  F1-Weighted: 0.0580\n",
      "  Training Time: 3.77s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1460\n",
      "  F1-Macro: 0.0552\n",
      "  F1-Weighted: 0.0549\n",
      "  Training Time: 0.01s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1420\n",
      "  F1-Macro: 0.0783\n",
      "  F1-Weighted: 0.0791\n",
      "  Training Time: 36.62s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1255\n",
      "  F1-Macro: 0.1179\n",
      "  F1-Weighted: 0.1154\n",
      "  Training Time: 0.28s\n",
      "\n",
      "[Combination 33/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: NOISE\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1110\n",
      "  F1-Macro: 0.0220\n",
      "  F1-Weighted: 0.0247\n",
      "  Training Time: 3.92s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1010\n",
      "  F1-Macro: 0.0300\n",
      "  F1-Weighted: 0.0299\n",
      "  Training Time: 0.01s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1040\n",
      "  F1-Macro: 0.0188\n",
      "  F1-Weighted: 0.0196\n",
      "  Training Time: 45.12s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1040\n",
      "  F1-Macro: 0.0509\n",
      "  F1-Weighted: 0.0505\n",
      "  Training Time: 0.25s\n",
      "\n",
      "[Combination 34/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: SCALING_0.8\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1280\n",
      "  F1-Macro: 0.0469\n",
      "  F1-Weighted: 0.0497\n",
      "  Training Time: 3.85s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1575\n",
      "  F1-Macro: 0.0607\n",
      "  F1-Weighted: 0.0637\n",
      "  Training Time: 0.01s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1160\n",
      "  F1-Macro: 0.0389\n",
      "  F1-Weighted: 0.0418\n",
      "  Training Time: 47.72s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.0875\n",
      "  F1-Macro: 0.0486\n",
      "  F1-Weighted: 0.0490\n",
      "  Training Time: 0.24s\n",
      "\n",
      "[Combination 35/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: OCCLUSION_25\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1335\n",
      "  F1-Macro: 0.0531\n",
      "  F1-Weighted: 0.0591\n",
      "  Training Time: 3.90s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1665\n",
      "  F1-Macro: 0.0640\n",
      "  F1-Weighted: 0.0720\n",
      "  Training Time: 0.01s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1300\n",
      "  F1-Macro: 0.0552\n",
      "  F1-Weighted: 0.0621\n",
      "  Training Time: 44.23s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1180\n",
      "  F1-Macro: 0.1073\n",
      "  F1-Weighted: 0.1096\n",
      "  Training Time: 0.23s\n",
      "\n",
      "[Combination 36/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: ALL_COMBINED\n",
      "FEATURE TYPE: RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 2\n",
      "Test samples: 2000, Features: 2\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1465\n",
      "  F1-Macro: 0.1099\n",
      "  F1-Weighted: 0.1092\n",
      "  Training Time: 3.74s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1430\n",
      "  F1-Macro: 0.0807\n",
      "  F1-Weighted: 0.0807\n",
      "  Training Time: 0.01s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1385\n",
      "  F1-Macro: 0.1065\n",
      "  F1-Weighted: 0.1063\n",
      "  Training Time: 43.85s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1135\n",
      "  F1-Macro: 0.1128\n",
      "  F1-Weighted: 0.1122\n",
      "  Training Time: 0.28s\n",
      "\n",
      "####################################################################################################\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "####################################################################################################\n",
      "\n",
      "[Combination 37/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: ORIGINAL\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.4795\n",
      "  F1-Macro: 0.4524\n",
      "  F1-Weighted: 0.4629\n",
      "  Training Time: 2.14s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.4535\n",
      "  F1-Macro: 0.4229\n",
      "  F1-Weighted: 0.4338\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.4780\n",
      "  F1-Macro: 0.4601\n",
      "  F1-Weighted: 0.4701\n",
      "  Training Time: 68.75s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.4575\n",
      "  F1-Macro: 0.4376\n",
      "  F1-Weighted: 0.4484\n",
      "  Training Time: 0.22s\n",
      "\n",
      "[Combination 38/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: ROTATION_15\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1270\n",
      "  F1-Macro: 0.0783\n",
      "  F1-Weighted: 0.0741\n",
      "  Training Time: 2.09s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1520\n",
      "  F1-Macro: 0.0687\n",
      "  F1-Weighted: 0.0644\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1140\n",
      "  F1-Macro: 0.0555\n",
      "  F1-Weighted: 0.0538\n",
      "  Training Time: 46.87s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1710\n",
      "  F1-Macro: 0.1251\n",
      "  F1-Weighted: 0.1178\n",
      "  Training Time: 0.21s\n",
      "\n",
      "[Combination 39/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: NOISE\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1145\n",
      "  F1-Macro: 0.0205\n",
      "  F1-Weighted: 0.0235\n",
      "  Training Time: 2.07s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.0965\n",
      "  F1-Macro: 0.0176\n",
      "  F1-Weighted: 0.0170\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.0965\n",
      "  F1-Macro: 0.0176\n",
      "  F1-Weighted: 0.0170\n",
      "  Training Time: 42.17s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1180\n",
      "  F1-Macro: 0.0706\n",
      "  F1-Weighted: 0.0691\n",
      "  Training Time: 0.20s\n",
      "\n",
      "[Combination 40/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: SCALING_0.8\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2950\n",
      "  F1-Macro: 0.2467\n",
      "  F1-Weighted: 0.2553\n",
      "  Training Time: 2.14s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2670\n",
      "  F1-Macro: 0.2176\n",
      "  F1-Weighted: 0.2254\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2720\n",
      "  F1-Macro: 0.2188\n",
      "  F1-Weighted: 0.2273\n",
      "  Training Time: 37.78s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2810\n",
      "  F1-Macro: 0.2296\n",
      "  F1-Weighted: 0.2391\n",
      "  Training Time: 0.21s\n",
      "\n",
      "[Combination 41/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: OCCLUSION_25\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.4440\n",
      "  F1-Macro: 0.4104\n",
      "  F1-Weighted: 0.4320\n",
      "  Training Time: 2.11s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.4365\n",
      "  F1-Macro: 0.4025\n",
      "  F1-Weighted: 0.4224\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.4420\n",
      "  F1-Macro: 0.4133\n",
      "  F1-Weighted: 0.4338\n",
      "  Training Time: 36.04s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.4350\n",
      "  F1-Macro: 0.4072\n",
      "  F1-Weighted: 0.4280\n",
      "  Training Time: 0.21s\n",
      "\n",
      "[Combination 42/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: ORIGINAL\n",
      "TEST SET: ALL_COMBINED\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.0795\n",
      "  F1-Macro: 0.0230\n",
      "  F1-Weighted: 0.0246\n",
      "  Training Time: 2.10s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1070\n",
      "  F1-Macro: 0.0230\n",
      "  F1-Weighted: 0.0239\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1045\n",
      "  F1-Macro: 0.0190\n",
      "  F1-Weighted: 0.0199\n",
      "  Training Time: 40.02s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1085\n",
      "  F1-Macro: 0.0608\n",
      "  F1-Weighted: 0.0622\n",
      "  Training Time: 0.21s\n",
      "\n",
      "[Combination 43/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: ORIGINAL\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.3905\n",
      "  F1-Macro: 0.3576\n",
      "  F1-Weighted: 0.3651\n",
      "  Training Time: 2.66s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.3320\n",
      "  F1-Macro: 0.2972\n",
      "  F1-Weighted: 0.3032\n",
      "  Training Time: 0.08s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.4145\n",
      "  F1-Macro: 0.3779\n",
      "  F1-Weighted: 0.3879\n",
      "  Training Time: 53.15s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.3980\n",
      "  F1-Macro: 0.3736\n",
      "  F1-Weighted: 0.3835\n",
      "  Training Time: 0.28s\n",
      "\n",
      "[Combination 44/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: ROTATION_15\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.3205\n",
      "  F1-Macro: 0.2844\n",
      "  F1-Weighted: 0.2872\n",
      "  Training Time: 2.72s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2705\n",
      "  F1-Macro: 0.2309\n",
      "  F1-Weighted: 0.2329\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.3525\n",
      "  F1-Macro: 0.3356\n",
      "  F1-Weighted: 0.3423\n",
      "  Training Time: 68.16s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.3435\n",
      "  F1-Macro: 0.3351\n",
      "  F1-Weighted: 0.3423\n",
      "  Training Time: 0.25s\n",
      "\n",
      "[Combination 45/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: NOISE\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2500\n",
      "  F1-Macro: 0.1679\n",
      "  F1-Weighted: 0.1733\n",
      "  Training Time: 2.62s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2070\n",
      "  F1-Macro: 0.1446\n",
      "  F1-Weighted: 0.1461\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2430\n",
      "  F1-Macro: 0.1876\n",
      "  F1-Weighted: 0.1954\n",
      "  Training Time: 29.02s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1935\n",
      "  F1-Macro: 0.1797\n",
      "  F1-Weighted: 0.1824\n",
      "  Training Time: 0.25s\n",
      "\n",
      "[Combination 46/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: SCALING_0.8\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.3765\n",
      "  F1-Macro: 0.3409\n",
      "  F1-Weighted: 0.3484\n",
      "  Training Time: 2.62s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.3070\n",
      "  F1-Macro: 0.2713\n",
      "  F1-Weighted: 0.2758\n",
      "  Training Time: 0.09s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.4055\n",
      "  F1-Macro: 0.3686\n",
      "  F1-Weighted: 0.3779\n",
      "  Training Time: 50.01s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.4010\n",
      "  F1-Macro: 0.3738\n",
      "  F1-Weighted: 0.3838\n",
      "  Training Time: 0.20s\n",
      "\n",
      "[Combination 47/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: OCCLUSION_25\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.3750\n",
      "  F1-Macro: 0.3368\n",
      "  F1-Weighted: 0.3511\n",
      "  Training Time: 2.66s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.3200\n",
      "  F1-Macro: 0.2849\n",
      "  F1-Weighted: 0.2952\n",
      "  Training Time: 0.09s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.4035\n",
      "  F1-Macro: 0.3616\n",
      "  F1-Weighted: 0.3804\n",
      "  Training Time: 36.49s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.4075\n",
      "  F1-Macro: 0.3783\n",
      "  F1-Weighted: 0.3966\n",
      "  Training Time: 0.44s\n",
      "\n",
      "[Combination 48/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: MIXED_AUGMENTED\n",
      "TEST SET: ALL_COMBINED\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1655\n",
      "  F1-Macro: 0.1168\n",
      "  F1-Weighted: 0.1167\n",
      "  Training Time: 2.72s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1485\n",
      "  F1-Macro: 0.1024\n",
      "  F1-Weighted: 0.1013\n",
      "  Training Time: 0.08s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1355\n",
      "  F1-Macro: 0.0888\n",
      "  F1-Weighted: 0.0892\n",
      "  Training Time: 30.47s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1240\n",
      "  F1-Macro: 0.0907\n",
      "  F1-Weighted: 0.0903\n",
      "  Training Time: 0.19s\n",
      "\n",
      "[Combination 49/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: ORIGINAL\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.0675\n",
      "  F1-Macro: 0.0441\n",
      "  F1-Weighted: 0.0434\n",
      "  Training Time: 3.25s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2340\n",
      "  F1-Macro: 0.1525\n",
      "  F1-Weighted: 0.1561\n",
      "  Training Time: 0.08s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2005\n",
      "  F1-Macro: 0.1319\n",
      "  F1-Weighted: 0.1352\n",
      "  Training Time: 49.78s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2335\n",
      "  F1-Macro: 0.1689\n",
      "  F1-Weighted: 0.1746\n",
      "  Training Time: 0.20s\n",
      "\n",
      "[Combination 50/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: ROTATION_15\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1705\n",
      "  F1-Macro: 0.1040\n",
      "  F1-Weighted: 0.1026\n",
      "  Training Time: 3.33s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2300\n",
      "  F1-Macro: 0.1415\n",
      "  F1-Weighted: 0.1435\n",
      "  Training Time: 0.10s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2120\n",
      "  F1-Macro: 0.1279\n",
      "  F1-Weighted: 0.1283\n",
      "  Training Time: 53.65s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2150\n",
      "  F1-Macro: 0.1370\n",
      "  F1-Weighted: 0.1370\n",
      "  Training Time: 0.25s\n",
      "\n",
      "[Combination 51/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: NOISE\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.1080\n",
      "  F1-Macro: 0.0195\n",
      "  F1-Weighted: 0.0211\n",
      "  Training Time: 3.32s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.1290\n",
      "  F1-Macro: 0.0508\n",
      "  F1-Weighted: 0.0516\n",
      "  Training Time: 0.08s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1375\n",
      "  F1-Macro: 0.0608\n",
      "  F1-Weighted: 0.0608\n",
      "  Training Time: 62.77s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.1380\n",
      "  F1-Macro: 0.0904\n",
      "  F1-Weighted: 0.0888\n",
      "  Training Time: 0.27s\n",
      "\n",
      "[Combination 52/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: SCALING_0.8\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.0720\n",
      "  F1-Macro: 0.0175\n",
      "  F1-Weighted: 0.0170\n",
      "  Training Time: 3.15s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2155\n",
      "  F1-Macro: 0.1500\n",
      "  F1-Weighted: 0.1531\n",
      "  Training Time: 0.09s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.1780\n",
      "  F1-Macro: 0.1370\n",
      "  F1-Weighted: 0.1371\n",
      "  Training Time: 39.13s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2300\n",
      "  F1-Macro: 0.1677\n",
      "  F1-Weighted: 0.1720\n",
      "  Training Time: 0.25s\n",
      "\n",
      "[Combination 53/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: OCCLUSION_25\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.0670\n",
      "  F1-Macro: 0.0390\n",
      "  F1-Weighted: 0.0402\n",
      "  Training Time: 3.31s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2475\n",
      "  F1-Macro: 0.1637\n",
      "  F1-Weighted: 0.1763\n",
      "  Training Time: 0.08s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2075\n",
      "  F1-Macro: 0.1335\n",
      "  F1-Weighted: 0.1457\n",
      "  Training Time: 52.64s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2400\n",
      "  F1-Macro: 0.1696\n",
      "  F1-Weighted: 0.1797\n",
      "  Training Time: 0.24s\n",
      "\n",
      "[Combination 54/54]\n",
      "\n",
      "================================================================================\n",
      "TRAINING SET: COMBINED_AUGMENTED\n",
      "TEST SET: ALL_COMBINED\n",
      "FEATURE TYPE: COMBINED_HOUGH_RANSAC\n",
      "================================================================================\n",
      "Train samples: 10000, Features: 8\n",
      "Test samples: 2000, Features: 8\n",
      "\n",
      "Training SVM_RBF...\n",
      "  Accuracy: 0.2630\n",
      "  F1-Macro: 0.2244\n",
      "  F1-Weighted: 0.2255\n",
      "  Training Time: 3.37s\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.2565\n",
      "  F1-Macro: 0.2095\n",
      "  F1-Weighted: 0.2126\n",
      "  Training Time: 0.07s\n",
      "\n",
      "Training MLP...\n",
      "  Accuracy: 0.2480\n",
      "  F1-Macro: 0.2243\n",
      "  F1-Weighted: 0.2253\n",
      "  Training Time: 48.06s\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.2230\n",
      "  F1-Macro: 0.2094\n",
      "  F1-Weighted: 0.2103\n",
      "  Training Time: 0.20s\n",
      "\n",
      "Step 5: Saving all results...\n",
      "✓ Saved results to ./geometric_results\\Hough_Transform_classification_results.txt\n",
      "✓ Saved results to ./geometric_results\\RANSAC_classification_results.txt\n",
      "✓ Saved results to ./geometric_results\\Combined_Hough_RANSAC_classification_results.txt\n",
      "\n",
      "Step 6: Generating summary report...\n",
      "✓ Saved summary report to ./geometric_results\\SUMMARY_REPORT.txt\n",
      "\n",
      "====================================================================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY!\n",
      "====================================================================================================\n",
      "Total Execution Time: 5724.06 seconds (95.4 minutes)\n",
      "Total Combinations Evaluated: 3 train x 6 test x 3 features = 54\n",
      "Total Model Trainings: 270 (5 models per combination)\n",
      "\n",
      "All results saved in: ./geometric_results\n",
      "\n",
      "Generated files:\n",
      "  - Visualizations: ./geometric_results\\visualizations\n",
      "  - Hough_Transform_classification_results.txt (18 combinations)\n",
      "  - RANSAC_classification_results.txt (18 combinations)\n",
      "  - Combined_Hough_RANSAC_classification_results.txt (18 combinations)\n",
      "  - SUMMARY_REPORT.txt (Overall best results)\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "PROCESSED_DIR = './data/processed'\n",
    "RESULTS_DIR = './geometric_results'\n",
    "DATASET_NAME = 'mnist'\n",
    "TRAIN_SAMPLES = 10000\n",
    "TEST_SAMPLES = 2000\n",
    "N_VISUAL_SAMPLES = 5\n",
    "SEED = 42\n",
    "\n",
    "# Training and test set combinations\n",
    "TRAIN_TYPES = ['original', 'mixed_augmented', 'combined_augmented']\n",
    "TEST_TYPES = ['original', 'rotation_15', 'noise', 'scaling_0.8', 'occlusion_25', 'all_combined']\n",
    "\n",
    "np.random.seed(SEED)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# ==================== GEOMETRY FEATURE EXTRACTION ====================\n",
    "class GeometryExtractor:\n",
    "    def __init__(self):\n",
    "        self.results_dir = RESULTS_DIR\n",
    "        \n",
    "    def _convert_to_gray(self, img):\n",
    "        \"\"\"Convert image to grayscale uint8\"\"\"\n",
    "        if len(img.shape) == 3 and img.shape[-1] == 3:\n",
    "            return cv2.cvtColor((img * 255).astype('uint8'), cv2.COLOR_RGB2GRAY)\n",
    "        return (img.squeeze() * 255).astype('uint8')\n",
    "    \n",
    "    def extract_hough_features(self, gray):\n",
    "        \"\"\"Extract Hough Transform features\"\"\"\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        vis = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Lines detection\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi/180, 30, 20, 10)\n",
    "        num_lines, lengths, angles = 0, [], []\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "                cv2.line(vis, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "                lengths.append(np.hypot(x2 - x1, y2 - y1))\n",
    "                angles.append(abs(np.degrees(np.arctan2(y2 - y1, x2 - x1))))\n",
    "            num_lines = len(lines)\n",
    "        \n",
    "        # Circles detection\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 2)\n",
    "        circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, 1.2, gray.shape[0] // 6,\n",
    "                                   param1=50, param2=30, minRadius=5, maxRadius=50)\n",
    "        num_circles, avg_radius = 0, 0\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for (x, y, r) in circles[0, :]:\n",
    "                cv2.circle(vis, (x, y), r, (0, 0, 255), 1)\n",
    "            num_circles = len(circles[0])\n",
    "            avg_radius = np.mean(circles[0][:, 2])\n",
    "        \n",
    "        # Edge density\n",
    "        h, w = gray.shape\n",
    "        edge_density = np.sum(edges > 0) / (h * w)\n",
    "        \n",
    "        features = {\n",
    "            'hough_num_lines': num_lines,\n",
    "            'hough_mean_length': np.mean(lengths) if lengths else 0,\n",
    "            'hough_mean_angle': np.mean(angles) if angles else 0,\n",
    "            'hough_num_circles': num_circles,\n",
    "            'hough_avg_radius': avg_radius,\n",
    "            'hough_edge_density': edge_density\n",
    "        }\n",
    "        return features, vis\n",
    "    \n",
    "    def extract_ransac_features(self, gray):\n",
    "        \"\"\"Extract RANSAC features\"\"\"\n",
    "        vis = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        points = np.column_stack(np.where(edges > 0))\n",
    "        \n",
    "        if len(points) < 10:\n",
    "            return {'ransac_line_inlier_ratio': 0, 'ransac_circle_inlier_ratio': 0}, vis\n",
    "        \n",
    "        # Line fit with RANSAC\n",
    "        X, y = points[:, 1].reshape(-1, 1), points[:, 0]\n",
    "        line_inlier_ratio = 0\n",
    "        try:\n",
    "            ransac = RANSACRegressor(residual_threshold=3.0, random_state=SEED)\n",
    "            ransac.fit(X, y)\n",
    "            y_pred = ransac.predict(X)\n",
    "            line_inlier_ratio = np.sum(ransac.inlier_mask_) / len(points)\n",
    "            # Draw sample points\n",
    "            for x1, y1p in zip(X.flatten()[::10], y_pred[::10]):\n",
    "                cv2.circle(vis, (int(x1), int(y1p)), 1, (255, 0, 0), -1)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Circle fit with RANSAC (simplified)\n",
    "        circle_inlier_ratio = 0\n",
    "        for _ in range(10):\n",
    "            if len(points) < 3:\n",
    "                break\n",
    "            idx = np.random.choice(len(points), 3, replace=False)\n",
    "            x1, y1 = points[idx[0]]\n",
    "            x2, y2 = points[idx[1]]\n",
    "            x3, y3 = points[idx[2]]\n",
    "            A = x1*(y2-y3) - y1*(x2-x3) + x2*y3 - x3*y2\n",
    "            if A == 0:\n",
    "                continue\n",
    "            B = (x1**2+y1**2)*(y3-y2)+(x2**2+y2**2)*(y1-y3)+(x3**2+y3**2)*(y2-y1)\n",
    "            C = (x1**2+y1**2)*(x2-x3)+(x2**2+y2**2)*(x3-x1)+(x3**2+y3**2)*(x1-x2)\n",
    "            cx, cy = -B/(2*A), -C/(2*A)\n",
    "            r_est = np.sqrt((points[:,1]-cx)**2 + (points[:,0]-cy)**2)\n",
    "            if np.any(np.isnan(r_est)):\n",
    "                continue\n",
    "            inliers = np.abs(r_est - np.mean(r_est)) < 5\n",
    "            inlier_ratio = np.sum(inliers) / len(points)\n",
    "            if inlier_ratio > circle_inlier_ratio:\n",
    "                circle_inlier_ratio = inlier_ratio\n",
    "                cv2.circle(vis, (int(cx), int(cy)), int(np.mean(r_est)), (255, 255, 0), 1)\n",
    "        \n",
    "        return {\n",
    "            'ransac_line_inlier_ratio': line_inlier_ratio,\n",
    "            'ransac_circle_inlier_ratio': circle_inlier_ratio\n",
    "        }, vis\n",
    "    \n",
    "    def extract_combined_features(self, gray):\n",
    "        \"\"\"Extract combined Hough + RANSAC features\"\"\"\n",
    "        hough_feats, hough_vis = self.extract_hough_features(gray)\n",
    "        ransac_feats, ransac_vis = self.extract_ransac_features(gray)\n",
    "        combined_vis = cv2.addWeighted(hough_vis, 0.6, ransac_vis, 0.6, 0)\n",
    "        return {**hough_feats, **ransac_feats}, combined_vis\n",
    "    \n",
    "    def extract_all_features(self, images, labels):\n",
    "        \"\"\"Extract all geometry features from images\"\"\"\n",
    "        print(\"Extracting geometry features...\")\n",
    "        hough_features = []\n",
    "        ransac_features = []\n",
    "        combined_features = []\n",
    "        \n",
    "        for img in tqdm(images, desc=\"Processing images\"):\n",
    "            gray = self._convert_to_gray(img)\n",
    "            \n",
    "            # Extract all three types\n",
    "            h_feat, _ = self.extract_hough_features(gray)\n",
    "            r_feat, _ = self.extract_ransac_features(gray)\n",
    "            c_feat, _ = self.extract_combined_features(gray)\n",
    "            \n",
    "            hough_features.append(h_feat)\n",
    "            ransac_features.append(r_feat)\n",
    "            combined_features.append(c_feat)\n",
    "        \n",
    "        # Convert to DataFrames\n",
    "        df_hough = pd.DataFrame(hough_features)\n",
    "        df_ransac = pd.DataFrame(ransac_features)\n",
    "        df_combined = pd.DataFrame(combined_features)\n",
    "        \n",
    "        # Add labels\n",
    "        df_hough['label'] = labels\n",
    "        df_ransac['label'] = labels\n",
    "        df_combined['label'] = labels\n",
    "        \n",
    "        return df_hough, df_ransac, df_combined\n",
    "    \n",
    "    def save_visualization_samples(self, images, labels):\n",
    "        \"\"\"Save visualization samples for all geometry types\"\"\"\n",
    "        print(f\"\\nSaving {N_VISUAL_SAMPLES} visualization samples...\")\n",
    "        \n",
    "        # Create visualization directory\n",
    "        vis_dir = os.path.join(self.results_dir, 'visualizations')\n",
    "        os.makedirs(vis_dir, exist_ok=True)\n",
    "        \n",
    "        # Select random samples\n",
    "        indices = np.random.choice(len(images), N_VISUAL_SAMPLES, replace=False)\n",
    "        \n",
    "        for idx in indices:\n",
    "            img = images[idx]\n",
    "            label = labels[idx]\n",
    "            gray = self._convert_to_gray(img)\n",
    "            \n",
    "            # Extract all visualizations\n",
    "            _, hough_vis = self.extract_hough_features(gray)\n",
    "            _, ransac_vis = self.extract_ransac_features(gray)\n",
    "            _, combined_vis = self.extract_combined_features(gray)\n",
    "            \n",
    "            # Create figure\n",
    "            fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "            \n",
    "            # Original\n",
    "            axes[0].imshow(gray, cmap='gray')\n",
    "            axes[0].set_title(f'Original (Label: {label})')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Hough\n",
    "            axes[1].imshow(cv2.cvtColor(hough_vis, cv2.COLOR_BGR2RGB))\n",
    "            axes[1].set_title('Hough Transform')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            # RANSAC\n",
    "            axes[2].imshow(cv2.cvtColor(ransac_vis, cv2.COLOR_BGR2RGB))\n",
    "            axes[2].set_title('RANSAC')\n",
    "            axes[2].axis('off')\n",
    "            \n",
    "            # Combined\n",
    "            axes[3].imshow(cv2.cvtColor(combined_vis, cv2.COLOR_BGR2RGB))\n",
    "            axes[3].set_title('Combined (Hough + RANSAC)')\n",
    "            axes[3].axis('off')\n",
    "            \n",
    "            plt.suptitle(f'Geometry Detection Comparison - Sample {idx}', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            save_path = os.path.join(vis_dir, f'sample_{idx}_label_{label}.png')\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        print(f\"✓ Saved visualizations to {vis_dir}\")\n",
    "\n",
    "# ==================== MODEL TRAINING ====================\n",
    "class ModelTrainer:\n",
    "    def __init__(self, results_dir):\n",
    "        self.results_dir = results_dir\n",
    "        self.models = {\n",
    "            'SVM_RBF': SVC(kernel='rbf', random_state=SEED),\n",
    "            'LogisticRegression': LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "            'MLP': MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=200, random_state=SEED),\n",
    "            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1),\n",
    "            'LightGBM': lgb.LGBMClassifier(n_estimators=100, random_state=SEED, verbose=-1)\n",
    "        }\n",
    "    \n",
    "    def prepare_data(self, df):\n",
    "        \"\"\"Prepare features and labels\"\"\"\n",
    "        feature_cols = [c for c in df.columns if c != 'label']\n",
    "        X = df[feature_cols].fillna(0).values\n",
    "        y = df['label'].values\n",
    "        return X, y, feature_cols\n",
    "    \n",
    "    def train_and_evaluate(self, X_train, y_train, X_test, y_test, feature_type, train_type, test_type):\n",
    "        \"\"\"Train all models and evaluate\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TRAINING SET: {train_type.upper()}\")\n",
    "        print(f\"TEST SET: {test_type.upper()}\")\n",
    "        print(f\"FEATURE TYPE: {feature_type.upper()}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Train samples: {len(X_train)}, Features: {X_train.shape[1]}\")\n",
    "        print(f\"Test samples: {len(X_test)}, Features: {X_test.shape[1]}\")\n",
    "        \n",
    "        for model_name, model_class in [\n",
    "            ('SVM_RBF', lambda: SVC(kernel='rbf', random_state=SEED)),\n",
    "            ('LogisticRegression', lambda: LogisticRegression(max_iter=1000, random_state=SEED)),\n",
    "            ('MLP', lambda: MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=200, random_state=SEED)),\n",
    "            ('RandomForest', lambda: RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1))\n",
    "        ]:\n",
    "            print(f\"\\nTraining {model_name}...\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Create fresh model instance\n",
    "            model = model_class()\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            \n",
    "            train_time = time.time() - start_time\n",
    "            \n",
    "            # Metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "            f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            report = classification_report(y_test, y_pred, digits=4)\n",
    "            \n",
    "            results[model_name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'f1_macro': f1_macro,\n",
    "                'f1_weighted': f1_weighted,\n",
    "                'train_time': train_time,\n",
    "                'report': report,\n",
    "                'y_pred': y_pred\n",
    "            }\n",
    "            \n",
    "            print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"  F1-Macro: {f1_macro:.4f}\")\n",
    "            print(f\"  F1-Weighted: {f1_weighted:.4f}\")\n",
    "            print(f\"  Training Time: {train_time:.2f}s\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_results(self, all_results, feature_type):\n",
    "        \"\"\"Save comprehensive results to text file\"\"\"\n",
    "        output_path = os.path.join(self.results_dir, f'{feature_type}_classification_results.txt')\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(f\"{'='*100}\\n\")\n",
    "            f.write(f\"CLASSIFICATION RESULTS - {feature_type.upper()}\\n\")\n",
    "            f.write(f\"{'='*100}\\n\\n\")\n",
    "            f.write(f\"Dataset: {DATASET_NAME.upper()}\\n\")\n",
    "            f.write(f\"Training Samples: {TRAIN_SAMPLES}\\n\")\n",
    "            f.write(f\"Test Samples: {TEST_SAMPLES}\\n\\n\")\n",
    "            \n",
    "            # Group by training set\n",
    "            for train_type in TRAIN_TYPES:\n",
    "                f.write(f\"\\n{'#'*100}\\n\")\n",
    "                f.write(f\"TRAINING SET: {train_type.upper()}\\n\")\n",
    "                f.write(f\"{'#'*100}\\n\")\n",
    "                \n",
    "                for test_type in TEST_TYPES:\n",
    "                    key = (train_type, test_type)\n",
    "                    if key not in all_results:\n",
    "                        continue\n",
    "                    \n",
    "                    results = all_results[key]\n",
    "                    \n",
    "                    f.write(f\"\\n{'-'*100}\\n\")\n",
    "                    f.write(f\"TEST SET: {test_type.upper()}\\n\")\n",
    "                    f.write(f\"{'-'*100}\\n\\n\")\n",
    "                    \n",
    "                    for model_name, model_results in results.items():\n",
    "                        f.write(f\"\\n{'='*80}\\n\")\n",
    "                        f.write(f\"MODEL: {model_name}\\n\")\n",
    "                        f.write(f\"{'='*80}\\n\\n\")\n",
    "                        f.write(f\"Accuracy: {model_results['accuracy']:.4f}\\n\")\n",
    "                        f.write(f\"F1-Score (Macro): {model_results['f1_macro']:.4f}\\n\")\n",
    "                        f.write(f\"F1-Score (Weighted): {model_results['f1_weighted']:.4f}\\n\")\n",
    "                        f.write(f\"Training Time: {model_results['train_time']:.2f} seconds\\n\\n\")\n",
    "                        f.write(\"Classification Report:\\n\")\n",
    "                        f.write(model_results['report'])\n",
    "                        f.write(\"\\n\\n\")\n",
    "        \n",
    "        print(f\"✓ Saved results to {output_path}\")\n",
    "\n",
    "# ==================== MAIN PIPELINE ====================\n",
    "def main():\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"GEOMETRY-BASED CLASSIFICATION PIPELINE FOR {DATASET_NAME.upper()}\")\n",
    "    print(f\"3 Training Sets x 6 Test Sets = 18 Classifications per Model\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ==================== STEP 1: Load All Data ====================\n",
    "    print(f\"Step 1: Loading all {DATASET_NAME.upper()} datasets...\")\n",
    "    \n",
    "    all_train_data = {}\n",
    "    all_test_data = {}\n",
    "    \n",
    "    # Load all training sets\n",
    "    for train_type in TRAIN_TYPES:\n",
    "        train_path = os.path.join(PROCESSED_DIR, f'{DATASET_NAME}_train', f'{train_type}.pkl')\n",
    "        if not os.path.exists(train_path):\n",
    "            raise FileNotFoundError(f\"Training data not found at {train_path}\")\n",
    "        \n",
    "        with open(train_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Sample data\n",
    "        if len(data['images']) > TRAIN_SAMPLES:\n",
    "            indices = np.random.choice(len(data['images']), TRAIN_SAMPLES, replace=False)\n",
    "            all_train_data[train_type] = {\n",
    "                'images': data['images'][indices],\n",
    "                'labels': data['labels'][indices]\n",
    "            }\n",
    "        else:\n",
    "            all_train_data[train_type] = data\n",
    "        \n",
    "        print(f\"✓ Loaded {train_type}: {len(all_train_data[train_type]['images'])} samples\")\n",
    "    \n",
    "    # Load all test sets\n",
    "    for test_type in TEST_TYPES:\n",
    "        test_path = os.path.join(PROCESSED_DIR, f'{DATASET_NAME}_test', f'{test_type}.pkl')\n",
    "        if not os.path.exists(test_path):\n",
    "            raise FileNotFoundError(f\"Test data not found at {test_path}\")\n",
    "        \n",
    "        with open(test_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Sample data\n",
    "        if len(data['images']) > TEST_SAMPLES:\n",
    "            indices = np.random.choice(len(data['images']), TEST_SAMPLES, replace=False)\n",
    "            all_test_data[test_type] = {\n",
    "                'images': data['images'][indices],\n",
    "                'labels': data['labels'][indices]\n",
    "            }\n",
    "        else:\n",
    "            all_test_data[test_type] = data\n",
    "        \n",
    "        print(f\"✓ Loaded {test_type}: {len(all_test_data[test_type]['images'])} samples\")\n",
    "    \n",
    "    # ==================== STEP 2: Save Visualizations ====================\n",
    "    print(f\"\\nStep 2: Saving visualization samples...\")\n",
    "    \n",
    "    extractor = GeometryExtractor()\n",
    "    \n",
    "    # Use original test set for visualizations\n",
    "    test_images = all_test_data['original']['images'][:50]\n",
    "    test_labels = all_test_data['original']['labels'][:50]\n",
    "    extractor.save_visualization_samples(test_images, test_labels)\n",
    "    \n",
    "    # ==================== STEP 3: Extract Features for All Sets ====================\n",
    "    print(f\"\\nStep 3: Extracting geometry features for all datasets...\")\n",
    "    \n",
    "    all_train_features = {}\n",
    "    all_test_features = {}\n",
    "    \n",
    "    # Extract features for all training sets\n",
    "    for train_type in TRAIN_TYPES:\n",
    "        print(f\"\\n  Processing training set: {train_type}\")\n",
    "        images = all_train_data[train_type]['images']\n",
    "        labels = all_train_data[train_type]['labels']\n",
    "        \n",
    "        hough_df, ransac_df, combined_df = extractor.extract_all_features(images, labels)\n",
    "        \n",
    "        all_train_features[train_type] = {\n",
    "            'hough': hough_df,\n",
    "            'ransac': ransac_df,\n",
    "            'combined': combined_df\n",
    "        }\n",
    "    \n",
    "    # Extract features for all test sets\n",
    "    for test_type in TEST_TYPES:\n",
    "        print(f\"\\n  Processing test set: {test_type}\")\n",
    "        images = all_test_data[test_type]['images']\n",
    "        labels = all_test_data[test_type]['labels']\n",
    "        \n",
    "        hough_df, ransac_df, combined_df = extractor.extract_all_features(images, labels)\n",
    "        \n",
    "        all_test_features[test_type] = {\n",
    "            'hough': hough_df,\n",
    "            'ransac': ransac_df,\n",
    "            'combined': combined_df\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n✓ Feature extraction completed for all datasets\")\n",
    "    \n",
    "    # ==================== STEP 4: Train Models (3 x 6 = 18 combinations) ====================\n",
    "    print(f\"\\nStep 4: Training and evaluating models...\")\n",
    "    print(f\"Total combinations: {len(TRAIN_TYPES)} train x {len(TEST_TYPES)} test = {len(TRAIN_TYPES) * len(TEST_TYPES)}\")\n",
    "    \n",
    "    trainer = ModelTrainer(RESULTS_DIR)\n",
    "    \n",
    "    # Feature types to evaluate\n",
    "    feature_types = ['hough', 'ransac', 'combined']\n",
    "    feature_names = {\n",
    "        'hough': 'Hough_Transform',\n",
    "        'ransac': 'RANSAC',\n",
    "        'combined': 'Combined_Hough_RANSAC'\n",
    "    }\n",
    "    \n",
    "    # Store all results\n",
    "    all_results_by_feature = {\n",
    "        'hough': {},\n",
    "        'ransac': {},\n",
    "        'combined': {}\n",
    "    }\n",
    "    \n",
    "    combination_count = 0\n",
    "    total_combinations = len(TRAIN_TYPES) * len(TEST_TYPES) * len(feature_types)\n",
    "    \n",
    "    # Train for each feature type\n",
    "    for feat_type in feature_types:\n",
    "        print(f\"\\n{'#'*100}\")\n",
    "        print(f\"FEATURE TYPE: {feature_names[feat_type].upper()}\")\n",
    "        print(f\"{'#'*100}\")\n",
    "        \n",
    "        # For each training set\n",
    "        for train_type in TRAIN_TYPES:\n",
    "            train_df = all_train_features[train_type][feat_type]\n",
    "            X_train, y_train, _ = trainer.prepare_data(train_df)\n",
    "            \n",
    "            # For each test set\n",
    "            for test_type in TEST_TYPES:\n",
    "                combination_count += 1\n",
    "                print(f\"\\n[Combination {combination_count}/{total_combinations}]\")\n",
    "                \n",
    "                test_df = all_test_features[test_type][feat_type]\n",
    "                X_test, y_test, _ = trainer.prepare_data(test_df)\n",
    "                \n",
    "                # Train and evaluate\n",
    "                results = trainer.train_and_evaluate(\n",
    "                    X_train, y_train, X_test, y_test,\n",
    "                    feature_names[feat_type], train_type, test_type\n",
    "                )\n",
    "                \n",
    "                all_results_by_feature[feat_type][(train_type, test_type)] = results\n",
    "    \n",
    "    # ==================== STEP 5: Save Results ====================\n",
    "    print(f\"\\nStep 5: Saving all results...\")\n",
    "    \n",
    "    for feat_type in feature_types:\n",
    "        trainer.save_results(all_results_by_feature[feat_type], feature_names[feat_type])\n",
    "    \n",
    "    # ==================== STEP 6: Summary Report ====================\n",
    "    print(f\"\\nStep 6: Generating summary report...\")\n",
    "    \n",
    "    summary_path = os.path.join(RESULTS_DIR, 'SUMMARY_REPORT.txt')\n",
    "    \n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(f\"{'='*100}\\n\")\n",
    "        f.write(f\"GEOMETRY-BASED CLASSIFICATION - COMPREHENSIVE SUMMARY\\n\")\n",
    "        f.write(f\"{'='*100}\\n\\n\")\n",
    "        f.write(f\"Dataset: {DATASET_NAME.upper()}\\n\")\n",
    "        f.write(f\"Training Samples per set: {TRAIN_SAMPLES}\\n\")\n",
    "        f.write(f\"Test Samples per set: {TEST_SAMPLES}\\n\")\n",
    "        f.write(f\"Training Sets: {', '.join(TRAIN_TYPES)}\\n\")\n",
    "        f.write(f\"Test Sets: {', '.join(TEST_TYPES)}\\n\")\n",
    "        f.write(f\"Total Combinations: {len(TRAIN_TYPES)} x {len(TEST_TYPES)} = {len(TRAIN_TYPES) * len(TEST_TYPES)} per feature type\\n\")\n",
    "        f.write(f\"Total Execution Time: {time.time() - start_time:.2f} seconds\\n\\n\")\n",
    "        \n",
    "        f.write(f\"{'='*100}\\n\")\n",
    "        f.write(f\"BEST PERFORMANCE BY FEATURE TYPE\\n\")\n",
    "        f.write(f\"{'='*100}\\n\\n\")\n",
    "        \n",
    "        overall_best = None\n",
    "        overall_best_f1 = 0\n",
    "        \n",
    "        for feat_type in feature_types:\n",
    "            f.write(f\"\\n{feature_names[feat_type]}:\\n\")\n",
    "            f.write(f\"{'-'*100}\\n\\n\")\n",
    "            \n",
    "            results = all_results_by_feature[feat_type]\n",
    "            \n",
    "            # Find best combination for this feature type\n",
    "            best_combo = None\n",
    "            best_f1 = 0\n",
    "            \n",
    "            for (train_type, test_type), models_results in results.items():\n",
    "                for model_name, model_results in models_results.items():\n",
    "                    if model_results['f1_macro'] > best_f1:\n",
    "                        best_f1 = model_results['f1_macro']\n",
    "                        best_combo = (train_type, test_type, model_name, model_results)\n",
    "                    \n",
    "                    if model_results['f1_macro'] > overall_best_f1:\n",
    "                        overall_best_f1 = model_results['f1_macro']\n",
    "                        overall_best = (feature_names[feat_type], train_type, test_type, model_name, model_results)\n",
    "            \n",
    "            if best_combo:\n",
    "                f.write(f\"Best Configuration:\\n\")\n",
    "                f.write(f\"  Training Set: {best_combo[0]}\\n\")\n",
    "                f.write(f\"  Test Set: {best_combo[1]}\\n\")\n",
    "                f.write(f\"  Model: {best_combo[2]}\\n\")\n",
    "                f.write(f\"  Accuracy: {best_combo[3]['accuracy']:.4f}\\n\")\n",
    "                f.write(f\"  F1-Macro: {best_combo[3]['f1_macro']:.4f}\\n\")\n",
    "                f.write(f\"  F1-Weighted: {best_combo[3]['f1_weighted']:.4f}\\n\")\n",
    "                f.write(f\"  Training Time: {best_combo[3]['train_time']:.2f}s\\n\\n\")\n",
    "            \n",
    "            # Average performance across all combinations\n",
    "            all_f1s = []\n",
    "            for models_results in results.values():\n",
    "                for model_results in models_results.values():\n",
    "                    all_f1s.append(model_results['f1_macro'])\n",
    "            \n",
    "            f.write(f\"Average F1-Macro across all combinations: {np.mean(all_f1s):.4f}\\n\")\n",
    "            f.write(f\"Std Dev: {np.std(all_f1s):.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"\\n{'='*100}\\n\")\n",
    "        f.write(f\"OVERALL BEST CONFIGURATION (ACROSS ALL FEATURE TYPES)\\n\")\n",
    "        f.write(f\"{'='*100}\\n\\n\")\n",
    "        \n",
    "        if overall_best:\n",
    "            f.write(f\"Feature Type: {overall_best[0]}\\n\")\n",
    "            f.write(f\"Training Set: {overall_best[1]}\\n\")\n",
    "            f.write(f\"Test Set: {overall_best[2]}\\n\")\n",
    "            f.write(f\"Model: {overall_best[3]}\\n\")\n",
    "            f.write(f\"Accuracy: {overall_best[4]['accuracy']:.4f}\\n\")\n",
    "            f.write(f\"F1-Macro: {overall_best[4]['f1_macro']:.4f}\\n\")\n",
    "            f.write(f\"F1-Weighted: {overall_best[4]['f1_weighted']:.4f}\\n\")\n",
    "            f.write(f\"Training Time: {overall_best[4]['train_time']:.2f}s\\n\")\n",
    "        \n",
    "        # Model comparison across all combinations\n",
    "        f.write(f\"\\n{'='*100}\\n\")\n",
    "        f.write(f\"MODEL PERFORMANCE COMPARISON (AVERAGE ACROSS ALL COMBINATIONS)\\n\")\n",
    "        f.write(f\"{'='*100}\\n\\n\")\n",
    "        \n",
    "        model_stats = {}\n",
    "        for feat_type in feature_types:\n",
    "            for models_results in all_results_by_feature[feat_type].values():\n",
    "                for model_name, model_results in models_results.items():\n",
    "                    if model_name not in model_stats:\n",
    "                        model_stats[model_name] = []\n",
    "                    model_stats[model_name].append(model_results['f1_macro'])\n",
    "        \n",
    "        for model_name in sorted(model_stats.keys()):\n",
    "            f1_scores = model_stats[model_name]\n",
    "            f.write(f\"{model_name:20s}: Mean F1={np.mean(f1_scores):.4f}, Std={np.std(f1_scores):.4f}, \"\n",
    "                   f\"Min={np.min(f1_scores):.4f}, Max={np.max(f1_scores):.4f}\\n\")\n",
    "    \n",
    "    print(f\"✓ Saved summary report to {summary_path}\")\n",
    "    \n",
    "    # ==================== COMPLETION ====================\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"{'='*100}\")\n",
    "    print(f\"Total Execution Time: {total_time:.2f} seconds ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"Total Combinations Evaluated: {len(TRAIN_TYPES)} train x {len(TEST_TYPES)} test x 3 features = {len(TRAIN_TYPES) * len(TEST_TYPES) * 3}\")\n",
    "    print(f\"Total Model Trainings: {len(TRAIN_TYPES) * len(TEST_TYPES) * 3 * 5} (5 models per combination)\")\n",
    "    print(f\"\\nAll results saved in: {RESULTS_DIR}\")\n",
    "    print(f\"\\nGenerated files:\")\n",
    "    print(f\"  - Visualizations: {os.path.join(RESULTS_DIR, 'visualizations')}\")\n",
    "    print(f\"  - Hough_Transform_classification_results.txt (18 combinations)\")\n",
    "    print(f\"  - RANSAC_classification_results.txt (18 combinations)\")\n",
    "    print(f\"  - Combined_Hough_RANSAC_classification_results.txt (18 combinations)\")\n",
    "    print(f\"  - SUMMARY_REPORT.txt (Overall best results)\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d119c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
